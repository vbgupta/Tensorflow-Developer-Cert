{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intoduction to NLP Fundamentals in Tensorflow\n",
    "\n",
    "Derive information from text or speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(y_true, preds):\n",
    "\n",
    "    return {\n",
    "        \"Accuracy Score\": (accuracy_score(y_true, preds) * 100),\n",
    "        \"Precision Score\": (precision_score(y_true, preds)* 100),\n",
    "        \"Recall Score\": (recall_score(y_true, preds)* 100),\n",
    "        \"F1-Score\": (f1_score(y_true, preds)* 100)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Text Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle's intro to NLP dataset - target [1 - disaster, 0 - not disaster]\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('data/nlp-getting-started/train.csv')\n",
    "test_data = pd.read_csv(\"data/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword location  \\\n",
       "2644  3796  destruction      NaN   \n",
       "2227  3185       deluge      NaN   \n",
       "5448  7769       police       UK   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle Data\n",
    "train_data_shuffled = train_data.sample(frac = 1, random_state=42)\n",
    "train_data_shuffled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples from each class?\n",
    "train_data_shuffled.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Stu Dorret's mudslide rubber tyre cake may have saved you #GBBO\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "This LA Startup Is So Hot that Their Flowers Come Straight from a Volcano http://t.co/R3PDdjPiEe via @LATechWatch\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@carneross indeed and a remarkably puny idea to place at the epicentre of a new post-capitalism epoch\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@pxnatosil @RenuncieDilma  Fatality!\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "'But right now you're only annoyed by them. If you actually hung out with them you'd see that they mean no harm.' @AudaciousSpunk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_data)-5)\n",
    "for row in train_data_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 6851, Validation: 762\n"
     ]
    }
   ],
   "source": [
    "# Split training data into train and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_data_shuffled[\"text\"].to_numpy(),\n",
    "                                                                                train_data_shuffled[\"target\"].to_numpy(), \n",
    "                                                                                test_size=0.1, random_state=42)\n",
    "print(f\"Train: {len(train_sentences)}, Validation: {len(val_sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization (Tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the avg number of tokens (words) in each sequence of the training set\n",
    "\n",
    "max_lenght = round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))\n",
    "max_lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 21:51:09.074129: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Setup the vectorization variables\n",
    "MAX_VOCAB_LENGTH = 10_000\n",
    "MAX_LENGTH = max_lenght\n",
    "OUTPUT_MODE = \"int\"\n",
    "\n",
    "\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=MAX_VOCAB_LENGTH, # how many words in the vocab\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\",\n",
    "                                    ngrams=None,\n",
    "                                    output_mode=OUTPUT_MODE,\n",
    "                                    output_sequence_length=MAX_LENGTH, # how long should the sequences be\n",
    "                                    pad_to_max_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "sample_sentence = \"There is a flood in my street\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layers\n",
    "\n",
    "Parameter to care for:\n",
    "* `input_dim`\n",
    "* `output_dim`\n",
    "* `input_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "OUTPUT_DIM = 128\n",
    "\n",
    "embedding = layers.Embedding(input_dim = MAX_VOCAB_LENGTH,\n",
    "                            output_dim = OUTPUT_DIM,\n",
    "                            input_length = MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " I fail to see how that would not bring the number of road fatalities down IMMENSELY    \n",
      "\n",
      "Embedded Sentence:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.03900011,  0.03718014, -0.01648239, ...,  0.01260573,\n",
       "         -0.01358408, -0.01213404],\n",
       "        [-0.01782079,  0.04413937,  0.03965607, ...,  0.00551749,\n",
       "          0.04487219, -0.02199703],\n",
       "        [-0.0431363 , -0.02011384,  0.03721175, ..., -0.04916177,\n",
       "         -0.00095408,  0.02266815],\n",
       "        ...,\n",
       "        [-0.01744239, -0.03556849, -0.02300822, ...,  0.04589213,\n",
       "         -0.00098292, -0.03430483],\n",
       "        [-0.04223281,  0.03443266, -0.00579477, ..., -0.04480303,\n",
       "         -0.03411742, -0.02580704],\n",
       "        [ 0.01858507, -0.00406301, -0.0001693 , ...,  0.02712229,\n",
       "          0.03324961, -0.0441456 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original Text:\\n {random_sentence}\\\n",
    "    \\n\\nEmbedded Sentence:\")\n",
    "\n",
    "# Embed\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Text Data - Running Multiple Experiments\n",
    "\n",
    "* Model 0: Naive Bayes (baseline)\n",
    "* Model 1: Feed Forward Neural Network (dense network)\n",
    "* Model 2: LSTM Model (RNN)\n",
    "* Model 3: GRU Model (RNN)\n",
    "* Model 4: Bidirectional-LSTM Model (RNN)\n",
    "* Model 5: 1-D Convolutional Network (CNN)\n",
    "* Model 6: Transfer Learning (Tensorflow Hub)\n",
    "* Model 7: Model 6, only 10% of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0: Naive Bayes - Baseline Model\n",
    "* `Multinomial Navie Bayes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create Tokenization and Modelling Pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # convert text to numbers\n",
    "    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model achieves an accuracy of: 79.27\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the baseline model\n",
    "\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Baseline model achieves an accuracy of: {baseline_score * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 79.26509186351706,\n",
       " 'Precision Score': 88.6178861788618,\n",
       " 'Recall Score': 62.643678160919535,\n",
       " 'F1-Score': 73.4006734006734}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Baseline Results\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_results = evaluate(y_true=val_labels,\n",
    "                            preds=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Feed-Forward Neural Net (Dense Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorboard Callback \n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create a directory to save TensoBoard API\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model with the Functional API\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape = (1, ), dtype = tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name = \"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_1.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20220530-215110\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 19ms/step - loss: 0.6102 - accuracy: 0.6938 - val_loss: 0.5349 - val_accuracy: 0.7546\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4405 - accuracy: 0.8190 - val_loss: 0.4700 - val_accuracy: 0.7861\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.3465 - accuracy: 0.8619 - val_loss: 0.4583 - val_accuracy: 0.7953\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.2844 - accuracy: 0.8875 - val_loss: 0.4655 - val_accuracy: 0.7874\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.2375 - accuracy: 0.9129 - val_loss: 0.4787 - val_accuracy: 0.7822\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "model_1_history = model_1.fit(\n",
    "    x = train_sentences,\n",
    "    y = train_labels,\n",
    "    epochs  = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR,\n",
    "                                            experiment_name = \"model_1_dense\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(762, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds_probs = model_1.predict(val_sentences)\n",
    "model_1_preds_probs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 1., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Porbs to label format\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_preds_probs))\n",
    "model_1_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0 Results:\n",
      " {'Accuracy Score': 79.26509186351706, 'Precision Score': 88.6178861788618, 'Recall Score': 62.643678160919535, 'F1-Score': 73.4006734006734}\n",
      "Model_1 Results:\n",
      " {'Accuracy Score': 78.21522309711287, 'Precision Score': 80.95238095238095, 'Recall Score': 68.39080459770115, 'F1-Score': 74.14330218068535}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_1_results = evaluate(val_labels, model_1_preds)\n",
    "print(f\"Model_0 Results:\\n {baseline_results}\")\n",
    "print(f\"Model_1 Results:\\n {model_1_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNN's)\n",
    "\n",
    "* Useful for sequence data\n",
    "* Premise - Use the representation of a previous input to aid the representation of a later input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create LSTM model\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape = (1, ), dtype = \"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "#x = layers.LSTM(64, return_sequences=True)(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "x = layers.Dense(64, activation = \"relu\")(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name = \"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,333,633\n",
      "Trainable params: 1,333,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_2.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20220530-215134\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 10s 34ms/step - loss: 0.2250 - accuracy: 0.9245 - val_loss: 0.5871 - val_accuracy: 0.7782\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 6s 27ms/step - loss: 0.1565 - accuracy: 0.9416 - val_loss: 0.6462 - val_accuracy: 0.7782\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.1278 - accuracy: 0.9526 - val_loss: 0.7901 - val_accuracy: 0.7756\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.1062 - accuracy: 0.9590 - val_loss: 0.8722 - val_accuracy: 0.7743\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0863 - accuracy: 0.9657 - val_loss: 0.9262 - val_accuracy: 0.7756\n"
     ]
    }
   ],
   "source": [
    "model_2_history = model_2.fit(\n",
    "    x = train_sentences,\n",
    "    y = train_labels,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR,\n",
    "    \"model_2_LSTM\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 77.55905511811024,\n",
       " 'Precision Score': 76.73716012084593,\n",
       " 'Recall Score': 72.98850574712644,\n",
       " 'F1-Score': 74.8159057437408}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results\n",
    "model_2_results = evaluate(y_true=val_labels,\n",
    "                           preds=tf.squeeze(tf.round(model_2.predict(val_sentences))))\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 79.26509186351706,\n",
       " 'Precision Score': 88.6178861788618,\n",
       " 'Recall Score': 62.643678160919535,\n",
       " 'F1-Score': 73.4006734006734}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape = (1, ), dtype = \"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "#x = layers.GRU(64, return_sequences=True)\n",
    "x = layers.GRU(64)(x)\n",
    "x = layers.Dense(64, activation = \"relu\")(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name = \"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,321,473\n",
      "Trainable params: 1,321,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 3 summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_3.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20220530-215206\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 25ms/step - loss: 0.1481 - accuracy: 0.9461 - val_loss: 0.8831 - val_accuracy: 0.7730\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.0805 - accuracy: 0.9686 - val_loss: 0.9053 - val_accuracy: 0.7730\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0721 - accuracy: 0.9736 - val_loss: 0.9240 - val_accuracy: 0.7690\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0558 - accuracy: 0.9775 - val_loss: 1.2574 - val_accuracy: 0.7756\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0573 - accuracy: 0.9739 - val_loss: 1.0403 - val_accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_3_history = model_3.fit(\n",
    "    x = train_sentences, \n",
    "    y = train_labels,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_3_GRU\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 76.77165354330708,\n",
       " 'Precision Score': 81.78438661710037,\n",
       " 'Recall Score': 63.2183908045977,\n",
       " 'F1-Score': 71.3128038897893}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_3_results = evaluate(y_true = val_labels,\n",
    "                            preds = tf.squeeze(tf.round(model_3.predict(val_sentences))))\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape = (1, ), dtype = \"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.GRU(64))(x)\n",
    "x = layers.Dense(64, activation = \"relu\")(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name = \"model_4_bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_bidirectional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 15, 128)          98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              74496     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,461,633\n",
      "Trainable params: 1,461,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 4 summary\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_4.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20220530-215235\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 22s 60ms/step - loss: 0.1008 - accuracy: 0.9670 - val_loss: 1.2085 - val_accuracy: 0.7677\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 13s 61ms/step - loss: 0.0504 - accuracy: 0.9765 - val_loss: 1.2635 - val_accuracy: 0.7664\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 11s 53ms/step - loss: 0.0500 - accuracy: 0.9774 - val_loss: 1.3482 - val_accuracy: 0.7559\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 11s 49ms/step - loss: 0.0428 - accuracy: 0.9803 - val_loss: 1.7628 - val_accuracy: 0.7703\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 11s 52ms/step - loss: 0.0425 - accuracy: 0.9796 - val_loss: 1.8033 - val_accuracy: 0.7612\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_4_history = model_4.fit(\n",
    "    x = train_sentences,\n",
    "    y = train_labels,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_4_bidirectional\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 3s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 76.11548556430446,\n",
       " 'Precision Score': 77.66666666666666,\n",
       " 'Recall Score': 66.95402298850574,\n",
       " 'F1-Score': 71.91358024691358}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_4_results = evaluate(y_true=val_labels,\n",
    "                            preds=tf.squeeze(tf.round(model_4.predict(val_sentences))))\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks for Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape = (1, ), dtype = \"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Conv1D(filters = 64, kernel_size = 5, strides = 1, \n",
    "                    activation = \"relu\", padding = \"valid\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name = \"model_5_conv1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_conv1d\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 11, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d_4   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,321,089\n",
      "Trainable params: 1,321,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 5 summary\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_5.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_5_conv1d/20220530-222111\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1172 - accuracy: 0.9663 - val_loss: 1.0612 - val_accuracy: 0.7559\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0580 - accuracy: 0.9762 - val_loss: 1.2969 - val_accuracy: 0.7546\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0495 - accuracy: 0.9796 - val_loss: 1.3953 - val_accuracy: 0.7520\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0462 - accuracy: 0.9787 - val_loss: 1.5736 - val_accuracy: 0.7507\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0440 - accuracy: 0.9801 - val_loss: 1.5535 - val_accuracy: 0.7520\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_5_history = model_5.fit(\n",
    "    x = train_sentences,\n",
    "    y = train_labels,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_5_conv1d\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 75.19685039370079,\n",
       " 'Precision Score': 74.61300309597523,\n",
       " 'Recall Score': 69.25287356321839,\n",
       " 'F1-Score': 71.83308494783903}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_5_evaluate = evaluate(y_true=val_labels,\n",
    "                            preds = tf.squeeze(tf.round(model_5.predict(val_sentences))))\n",
    "model_5_evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Tensorflow Hub Pre-trained Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # embed -> because this model helps with embedding, not classification, use dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentence encoder layer\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape = [],\n",
    "                                        dtype = tf.string,\n",
    "                                        trainable = False,\n",
    "                                        name = \"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = tf.keras.Sequential([\n",
    "                                sentence_encoder_layer,\n",
    "                                layers.Dense(64, activation = \"relu\"),\n",
    "                                layers.Dense(1, activation = \"sigmoid\")\n",
    "                            ], name = \"model_6_USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_6.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_6_USE/20220530-231537\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 16ms/step - loss: 0.5016 - accuracy: 0.7876 - val_loss: 0.4498 - val_accuracy: 0.8031\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.4137 - accuracy: 0.8171 - val_loss: 0.4352 - val_accuracy: 0.8163\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.3999 - accuracy: 0.8228 - val_loss: 0.4332 - val_accuracy: 0.8123\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.3914 - accuracy: 0.8282 - val_loss: 0.4337 - val_accuracy: 0.8110\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.3852 - accuracy: 0.8294 - val_loss: 0.4268 - val_accuracy: 0.8163\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_6_history = model_6.fit(\n",
    "    x = train_sentences,\n",
    "    y = train_labels,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_6_USE\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 81.62729658792651,\n",
       " 'Precision Score': 81.90184049079755,\n",
       " 'Recall Score': 76.72413793103449,\n",
       " 'F1-Score': 79.22848664688428}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_6_results = evaluate(y_true = val_labels,\n",
    "                            preds = tf.squeeze(tf.round(model_6.predict(val_sentences))))\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Life - We have little data to work with 🙁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset for 10% of the data only\n",
    "train_10_percent_split = int(0.1 * len(train_sentences))\n",
    "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
    "train_labels_10_percent = train_labels[:train_10_percent_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    406\n",
       "1    279\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the targets\n",
    "import numpy as np\n",
    "pd.Series(np.array(train_labels_10_percent)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7 -> Cloned Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = tf.keras.models.clone_model(model_6)\n",
    "\n",
    "#compile model\n",
    "model_7.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_7_USE_10_percent_data/20220530-234800\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 5s 64ms/step - loss: 0.6707 - accuracy: 0.6905 - val_loss: 0.6444 - val_accuracy: 0.7585\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.6006 - accuracy: 0.8015 - val_loss: 0.5860 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5271 - accuracy: 0.8146 - val_loss: 0.5323 - val_accuracy: 0.7756\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.4665 - accuracy: 0.8175 - val_loss: 0.5010 - val_accuracy: 0.7756\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.4255 - accuracy: 0.8248 - val_loss: 0.4855 - val_accuracy: 0.7782\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_7_history = model_7.fit(\n",
    "    x = train_sentences_10_percent,\n",
    "    y = train_labels_10_percent,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_7_USE_10_percent_data\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 4s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 77.82152230971128,\n",
       " 'Precision Score': 78.96440129449837,\n",
       " 'Recall Score': 70.11494252873564,\n",
       " 'F1-Score': 74.27701674277016}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_7_results = evaluate(y_true = val_labels,\n",
    "                            preds = tf.squeeze(tf.round(model_7.predict(val_sentences))))\n",
    "model_7_results             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>88.617886</td>\n",
       "      <td>62.643678</td>\n",
       "      <td>73.400673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_1_Dense</th>\n",
       "      <td>78.215223</td>\n",
       "      <td>80.952381</td>\n",
       "      <td>68.390805</td>\n",
       "      <td>74.143302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_2_LSTM</th>\n",
       "      <td>77.559055</td>\n",
       "      <td>76.737160</td>\n",
       "      <td>72.988506</td>\n",
       "      <td>74.815906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_3_GRU</th>\n",
       "      <td>76.771654</td>\n",
       "      <td>81.784387</td>\n",
       "      <td>63.218391</td>\n",
       "      <td>71.312804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_4_bidirectional</th>\n",
       "      <td>76.115486</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>66.954023</td>\n",
       "      <td>71.913580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_5_Conv1D</th>\n",
       "      <td>75.196850</td>\n",
       "      <td>74.613003</td>\n",
       "      <td>69.252874</td>\n",
       "      <td>71.833085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_6_USE</th>\n",
       "      <td>81.627297</td>\n",
       "      <td>81.901840</td>\n",
       "      <td>76.724138</td>\n",
       "      <td>79.228487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_7_USE_10%</th>\n",
       "      <td>77.821522</td>\n",
       "      <td>78.964401</td>\n",
       "      <td>70.114943</td>\n",
       "      <td>74.277017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Accuracy Score  Precision Score  Recall Score  \\\n",
       "Baseline                    79.265092        88.617886     62.643678   \n",
       "Model_1_Dense               78.215223        80.952381     68.390805   \n",
       "Model_2_LSTM                77.559055        76.737160     72.988506   \n",
       "Model_3_GRU                 76.771654        81.784387     63.218391   \n",
       "Model_4_bidirectional       76.115486        77.666667     66.954023   \n",
       "Model_5_Conv1D              75.196850        74.613003     69.252874   \n",
       "Model_6_USE                 81.627297        81.901840     76.724138   \n",
       "Model_7_USE_10%             77.821522        78.964401     70.114943   \n",
       "\n",
       "                        F1-Score  \n",
       "Baseline               73.400673  \n",
       "Model_1_Dense          74.143302  \n",
       "Model_2_LSTM           74.815906  \n",
       "Model_3_GRU            71.312804  \n",
       "Model_4_bidirectional  71.913580  \n",
       "Model_5_Conv1D         71.833085  \n",
       "Model_6_USE            79.228487  \n",
       "Model_7_USE_10%        74.277017  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_results = pd.DataFrame({\n",
    "    \"Baseline\": baseline_results,\n",
    "    \"Model_1_Dense\": model_1_results,\n",
    "    \"Model_2_LSTM\": model_2_results,\n",
    "    \"Model_3_GRU\": model_3_results,\n",
    "    \"Model_4_bidirectional\": model_4_results,\n",
    "    \"Model_5_Conv1D\": model_5_evaluate,\n",
    "    \"Model_6_USE\": model_6_results,\n",
    "    \"Model_7_USE_10%\": model_7_results\n",
    "})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_model_results.plot(kind = \"bar\", figsize = (10, 7)).legend(bbox_to_anchor = (1.0, 1.0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load NLP Models\n",
    "* HDF5 Format\n",
    "* The `Save Model` format - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# model_6.save(\"models/model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load this model in hdf5 format\n",
    "# loaded_model_6 = tf.keras.models.load_model(\"models/model_6.h5\",\n",
    "#                                             custom_objects = {\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_6_savedmodels_format/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_6_savedmodels_format/assets\n"
     ]
    }
   ],
   "source": [
    "# Save Model Format\n",
    "# model_6.save(\"models/model_6_savedmodels_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model_6_saved_model = tf.keras.models.load_model(\"models/model_6_savedmodels_format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the most wrong answer examples\n",
    "* If our best model is not perfect, what examples are it getting wrong\n",
    "* Which ones are the most wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 16ms/step\n",
      "24/24 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>predictions</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>That's the ultimate road to destruction</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>@SetZorah dad why dont you claim me that mean ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.927575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Crack in the path where I wiped out this morni...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>I liked a @YouTube video from @dannyonpc http:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>762 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  labels  predictions  \\\n",
       "0    DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0          0.0   \n",
       "1    FedEx no longer to transport bioterror germs i...       0          1.0   \n",
       "2    Gunmen kill four in El Salvador bus attack: Su...       1          1.0   \n",
       "3    @camilacabello97 Internally and externally scr...       1          0.0   \n",
       "4    Radiation emergency #preparedness starts with ...       1          1.0   \n",
       "..                                                 ...     ...          ...   \n",
       "757            That's the ultimate road to destruction       0          0.0   \n",
       "758  @SetZorah dad why dont you claim me that mean ...       0          0.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0          1.0   \n",
       "760  Crack in the path where I wiped out this morni...       0          1.0   \n",
       "761  I liked a @YouTube video from @dannyonpc http:...       0          0.0   \n",
       "\n",
       "     probabilities  \n",
       "0         0.258606  \n",
       "1         0.844572  \n",
       "2         0.992562  \n",
       "3         0.223227  \n",
       "4         0.774475  \n",
       "..             ...  \n",
       "757       0.124211  \n",
       "758       0.134450  \n",
       "759       0.927575  \n",
       "760       0.677772  \n",
       "761       0.125239  \n",
       "\n",
       "[762 rows x 4 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe with validation sentences, labels and best performing model predictions and probabilities\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    \"text\": val_sentences,\n",
    "    \"labels\": val_labels,\n",
    "    \"predictions\": tf.squeeze(tf.round(model_6.predict(val_sentences))),\n",
    "    \"probabilities\": tf.squeeze(model_6.predict(val_sentences))\n",
    "})\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>predictions</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.927575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.922627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.871318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Why are you deluged with low self-image? Take ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>I get to smoke my shit in peace</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  labels  predictions  \\\n",
       "759  FedEx will no longer transport bioterror patho...       0          1.0   \n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0          1.0   \n",
       "628  @noah_anyname That's where the concentration c...       0          1.0   \n",
       "49   @madonnamking RSPCA site multiple 7 story high...       0          1.0   \n",
       "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0          1.0   \n",
       "..                                                 ...     ...          ...   \n",
       "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1          0.0   \n",
       "23   Ron &amp; Fez - Dave's High School Crush https...       1          0.0   \n",
       "38   Why are you deluged with low self-image? Take ...       1          0.0   \n",
       "233                    I get to smoke my shit in peace       1          0.0   \n",
       "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1          0.0   \n",
       "\n",
       "     probabilities  \n",
       "759       0.927575  \n",
       "31        0.922627  \n",
       "628       0.908378  \n",
       "49        0.871318  \n",
       "109       0.856082  \n",
       "..             ...  \n",
       "244       0.050709  \n",
       "23        0.046186  \n",
       "38        0.044266  \n",
       "233       0.044215  \n",
       "411       0.044131  \n",
       "\n",
       "[140 rows x 4 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find wrong preds, and sort by pred probs\n",
    "most_wrong = val_df[val_df[\"labels\"] != val_df[\"predictions\"]].sort_values(\"probabilities\", ascending = False)\n",
    "most_wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "Pred: 0, Prob: 0.048589110374450684\n",
      "\n",
      "Text: Beauty Deals : http://t.co/eUd317Eptp #4552 Lot of 50Mixed Colors 7.5' Scissors FirstAid Princess Care Rescue TrÛ_ http://t.co/mAHkV79SmW\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Pred: 1, Prob: 0.6504212617874146\n",
      "\n",
      "Text: Stop using the money of tax layers of the country to feed bloody terrorist. Shot them and give a strong msg as other country does...\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Pred: 0, Prob: 0.05033646896481514\n",
      "\n",
      "Text: My boy @Fall_off_Cliff still got it man rumor has it he going back to DE ??\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Pred: 0, Prob: 0.07740994542837143\n",
      "\n",
      "Text: @eliistender10 @Splats although originally an April Fools jokethey're seriously considering making them after being inundated with requests\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Pred: 1, Prob: 0.5752593278884888\n",
      "\n",
      "Text: Kimanzi_: Breaking news! Unconfirmed! I just heard a loud bang nearby. in what appears to be a blast of wind from my neighbour's ass.\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Pred: 0, Prob: 0.21074330806732178\n",
      "\n",
      "Text: Himika Amase is the only prophet in the world who foresaw 'hijack in March' as it was on her Jps Twitter in Feb 2014. malyasiaairlines. ???\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Pred: 0, Prob: 0.11034831404685974\n",
      "\n",
      "Text: @thrillhho jsyk I haven't stopped thinking abt remus slumped against the bathroom door all day I was wrecked ??????????\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Pred: 0, Prob: 0.05930992588400841\n",
      "\n",
      "Text: If Tyuler Collins could become Andy Dirks before the 58 injuries..that would be uiseful\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Pred: 0, Prob: 0.37678369879722595\n",
      "\n",
      "Text: @BigBang_CBS ...wow...ok...um...that was like ice water blizzard snowstorm to the face.\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Pred: 1, Prob: 0.6961221694946289\n",
      "\n",
      "Text: Correction: Tent Collapse Story http://t.co/CMbNMvVDKl\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = test_data[\"text\"].to_list()\n",
    "\n",
    "# Making predictions of 10 test sentences and visualizing them\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "    pred_probs = tf.squeeze(model_6.predict([test_sample]))\n",
    "    pred = tf.round(pred_probs)\n",
    "    print(f\"Pred: {int(pred)}, Prob: {pred_probs}\\n\")\n",
    "    print(f\"Text: {test_sample}\\n\")\n",
    "    print(\"-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  id\n",
       "0                 Just happened a terrible car crash   0\n",
       "1  Heard about #earthquake is different cities, s...   2\n",
       "2  there is a forest fire at spot pond, geese are...   3\n",
       "3           Apocalypse lighting. #Spokane #wildfires   9\n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan  11"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Test Data\n",
    "test_data[[\"text\", \"id\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'target'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Submission File - Kaggle\n",
    "sub_file = pd.read_csv(\"data/nlp-getting-started/sample_submission.csv\")\n",
    "print(sub_file.columns)\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file = pd.DataFrame({\n",
    "    \"id\": test_data[\"id\"],\n",
    "    \"target\": tf.squeeze(tf.round(model_6.predict(test_data[\"text\"].to_list())))\n",
    "})\n",
    "submission_file[\"target\"] = submission_file[\"target\"].astype(int)\n",
    "submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file.to_csv(\"data/nlp-getting-started-submission-1.csv\", index = False) # 0.80570 -> accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Tweets from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "Elon's Tweet is: 0\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Tesla Plaid S cruising around Austin with volume at 11 is sublime\" #thanks elon\n",
    "\n",
    "answer = int(tf.squeeze(tf.round(model_6.predict([sentence]))))\n",
    "print(f\"Elon's Tweet is: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e2db2fe913eb9e94297199806106f5b16655b08f59047963fa319e06216a9ba"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('3.10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
