{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intoduction to NLP Fundamentals in Tensorflow\n",
    "\n",
    "Derive information from text or speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(y_true, preds):\n",
    "\n",
    "    return {\n",
    "        \"Accuracy Score\": (accuracy_score(y_true, preds) * 100),\n",
    "        \"Precision Score\": (precision_score(y_true, preds)* 100),\n",
    "        \"Recall Score\": (recall_score(y_true, preds)* 100),\n",
    "        \"F1-Score\": (f1_score(y_true, preds)* 100)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Text Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle's intro to NLP dataset - target [1 - disaster, 0 - not disaster]\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('data/nlp-getting-started/train.csv')\n",
    "test_data = pd.read_csv(\"data/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword location  \\\n",
       "2644  3796  destruction      NaN   \n",
       "2227  3185       deluge      NaN   \n",
       "5448  7769       police       UK   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle Data\n",
    "train_data_shuffled = train_data.sample(frac = 1, random_state=42)\n",
    "train_data_shuffled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples from each class?\n",
    "train_data_shuffled.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Palestinian Teen Killed Amid Protests Against Arson Attack http://t.co/okVsImoGic\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "#frontpage: #Bioterror lab faced secret sanctions. #RickPerry doesn't make the cut for @FoxNews #GOPDebate http://t.co/fZujg7sXJg @USATODAY\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "My emotions are a train wreck. My body is a train wreck. I'm a wreck\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "#Sismo DETECTADO #JapÌ_n 15:41:07 Seismic intensity 0 Iwate Miyagi JST #?? http://t.co/gMoUl9zQ2Q\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "A look at state actions a year after Ferguson's upheaval http://t.co/GZEkQWzijq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_data)-5)\n",
    "for row in train_data_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 6851, Validation: 762\n"
     ]
    }
   ],
   "source": [
    "# Split training data into train and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_data_shuffled[\"text\"].to_numpy(),\n",
    "                                                                                train_data_shuffled[\"target\"].to_numpy(), \n",
    "                                                                                test_size=0.1, random_state=42)\n",
    "print(f\"Train: {len(train_sentences)}, Validation: {len(val_sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization (Tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the avg number of tokens (words) in each sequence of the training set\n",
    "\n",
    "max_lenght = round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))\n",
    "max_lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 02:57:59.597618: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Setup the vectorization variables\n",
    "MAX_VOCAB_LENGTH = 10_000\n",
    "MAX_LENGTH = max_lenght\n",
    "OUTPUT_MODE = \"int\"\n",
    "\n",
    "\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=MAX_VOCAB_LENGTH, # how many words in the vocab\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\",\n",
    "                                    ngrams=None,\n",
    "                                    output_mode=OUTPUT_MODE,\n",
    "                                    output_sequence_length=MAX_LENGTH, # how long should the sequences be\n",
    "                                    pad_to_max_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "sample_sentence = \"There is a flood in my street\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layers\n",
    "\n",
    "Parameter to care for:\n",
    "* `input_dim`\n",
    "* `output_dim`\n",
    "* `input_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "OUTPUT_DIM = 128\n",
    "\n",
    "embedding = layers.Embedding(input_dim = MAX_VOCAB_LENGTH,\n",
    "                            output_dim = OUTPUT_DIM,\n",
    "                            input_length = MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " Lily Xo is a sexy cowgirl out in the sticks http://t.co/qew4c5M1xd View and download video    \n",
      "\n",
      "Embedded Sentence:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.01536043, -0.00791342,  0.03378456, ..., -0.028397  ,\n",
       "          0.0094022 ,  0.03407052],\n",
       "        [-0.01920433, -0.04355104,  0.01357626, ..., -0.04218745,\n",
       "         -0.02009963,  0.04114534],\n",
       "        [-0.02487618,  0.04923302,  0.01479255, ...,  0.03266704,\n",
       "         -0.01677847,  0.03054232],\n",
       "        ...,\n",
       "        [-0.03035313, -0.02886738, -0.00500046, ..., -0.01698917,\n",
       "          0.02262404,  0.00414308],\n",
       "        [ 0.01628763, -0.04540346, -0.01206819, ...,  0.04231675,\n",
       "          0.01388797, -0.03472651],\n",
       "        [-0.02964337, -0.00303084,  0.03832131, ...,  0.04769753,\n",
       "          0.04207382, -0.01451921]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original Text:\\n {random_sentence}\\\n",
    "    \\n\\nEmbedded Sentence:\")\n",
    "\n",
    "# Embed\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Text Data - Running Multiple Experiments\n",
    "\n",
    "* Model 0: Naive Bayes (baseline)\n",
    "* Model 1: Feed Forward Neural Network (dense network)\n",
    "* Model 2: LSTM Model (RNN)\n",
    "* Model 3: GRU Model (RNN)\n",
    "* Model 4: Bidirectional-LSTM Model (RNN)\n",
    "* Model 5: 1-D Convolutional Network (CNN)\n",
    "* Model 6: Transfer Learning (Tensorflow Hub)\n",
    "* Model 7: Model 6, only 10% of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0: Naive Bayes - Baseline Model\n",
    "* `Multinomial Navie Bayes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create Tokenization and Modelling Pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # convert text to numbers\n",
    "    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model achieves an accuracy of: 79.27\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the baseline model\n",
    "\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Baseline model achieves an accuracy of: {baseline_score * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 79.26509186351706,\n",
       " 'Precision Score': 88.6178861788618,\n",
       " 'Recall Score': 62.643678160919535,\n",
       " 'F1-Score': 73.4006734006734}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Baseline Results\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_results = evaluate(y_true=val_labels,\n",
    "                            preds=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Feed-Forward Neural Net (Dense Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorboard Callback \n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create a directory to save TensoBoard API\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model with the Functional API\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape = (1, ), dtype = tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name = \"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_1.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20220601-025802\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 20ms/step - loss: 0.6146 - accuracy: 0.6830 - val_loss: 0.5365 - val_accuracy: 0.7598\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4423 - accuracy: 0.8209 - val_loss: 0.4714 - val_accuracy: 0.7861\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.3477 - accuracy: 0.8606 - val_loss: 0.4552 - val_accuracy: 0.7953\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.2853 - accuracy: 0.8917 - val_loss: 0.4622 - val_accuracy: 0.7861\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.2384 - accuracy: 0.9108 - val_loss: 0.4807 - val_accuracy: 0.7822\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "model_1_history = model_1.fit(\n",
    "    x = train_sentences,\n",
    "    y = train_labels,\n",
    "    epochs  = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR,\n",
    "                                            experiment_name = \"model_1_dense\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(762, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds_probs = model_1.predict(val_sentences)\n",
    "model_1_preds_probs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 1., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Porbs to label format\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_preds_probs))\n",
    "model_1_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0 Results:\n",
      " {'Accuracy Score': 79.26509186351706, 'Precision Score': 88.6178861788618, 'Recall Score': 62.643678160919535, 'F1-Score': 73.4006734006734}\n",
      "Model_1 Results:\n",
      " {'Accuracy Score': 78.21522309711287, 'Precision Score': 81.59722222222221, 'Recall Score': 67.52873563218391, 'F1-Score': 73.89937106918238}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_1_results = evaluate(val_labels, model_1_preds)\n",
    "print(f\"Model_0 Results:\\n {baseline_results}\")\n",
    "print(f\"Model_1 Results:\\n {model_1_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNN's)\n",
    "\n",
    "* Useful for sequence data\n",
    "* Premise - Use the representation of a previous input to aid the representation of a later input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create LSTM model\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape = (1, ), dtype = \"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "#x = layers.LSTM(64, return_sequences=True)(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "x = layers.Dense(64, activation = \"relu\")(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name = \"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,333,633\n",
      "Trainable params: 1,333,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_2.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20220601-025825\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 16s 51ms/step - loss: 0.2175 - accuracy: 0.9250 - val_loss: 0.6095 - val_accuracy: 0.7822\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 8s 36ms/step - loss: 0.1517 - accuracy: 0.9429 - val_loss: 0.7018 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 0.1259 - accuracy: 0.9531 - val_loss: 0.6429 - val_accuracy: 0.7874\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 8s 37ms/step - loss: 0.1009 - accuracy: 0.9637 - val_loss: 0.7339 - val_accuracy: 0.7769\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 8s 37ms/step - loss: 0.0836 - accuracy: 0.9672 - val_loss: 1.4988 - val_accuracy: 0.7638\n"
     ]
    }
   ],
   "source": [
    "model_2_history = model_2.fit(\n",
    "    x = train_sentences,\n",
    "    y = train_labels,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR,\n",
    "    \"model_2_LSTM\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 76.37795275590551,\n",
       " 'Precision Score': 80.88235294117648,\n",
       " 'Recall Score': 63.2183908045977,\n",
       " 'F1-Score': 70.96774193548387}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results\n",
    "model_2_results = evaluate(y_true=val_labels,\n",
    "                           preds=tf.squeeze(tf.round(model_2.predict(val_sentences))))\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 79.26509186351706,\n",
       " 'Precision Score': 88.6178861788618,\n",
       " 'Recall Score': 62.643678160919535,\n",
       " 'F1-Score': 73.4006734006734}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape = (1, ), dtype = \"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "#x = layers.GRU(64, return_sequences=True)\n",
    "x = layers.GRU(64)(x)\n",
    "x = layers.Dense(64, activation = \"relu\")(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name = \"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,321,473\n",
      "Trainable params: 1,321,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 3 summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_3.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20220601-025916\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 14s 43ms/step - loss: 0.1602 - accuracy: 0.9365 - val_loss: 0.8394 - val_accuracy: 0.7677\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 8s 36ms/step - loss: 0.0774 - accuracy: 0.9721 - val_loss: 1.0614 - val_accuracy: 0.7730\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 8s 37ms/step - loss: 0.0634 - accuracy: 0.9743 - val_loss: 1.0051 - val_accuracy: 0.7690\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 8s 39ms/step - loss: 0.0546 - accuracy: 0.9765 - val_loss: 1.8307 - val_accuracy: 0.7415\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.0518 - accuracy: 0.9752 - val_loss: 1.4914 - val_accuracy: 0.7769\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_3_history = model_3.fit(\n",
    "    x = train_sentences, \n",
    "    y = train_labels,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_3_GRU\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 77.69028871391076,\n",
       " 'Precision Score': 79.47019867549669,\n",
       " 'Recall Score': 68.96551724137932,\n",
       " 'F1-Score': 73.84615384615384}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_3_results = evaluate(y_true = val_labels,\n",
    "                            preds = tf.squeeze(tf.round(model_3.predict(val_sentences))))\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape = (1, ), dtype = \"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.GRU(64))(x)\n",
    "x = layers.Dense(64, activation = \"relu\")(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name = \"model_4_bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_bidirectional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 15, 128)          98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              74496     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,461,633\n",
      "Trainable params: 1,461,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 4 summary\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_4.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20220601-030004\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 37s 97ms/step - loss: 0.1017 - accuracy: 0.9673 - val_loss: 1.3092 - val_accuracy: 0.7598\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 20s 92ms/step - loss: 0.0473 - accuracy: 0.9781 - val_loss: 1.9340 - val_accuracy: 0.7717\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 17s 79ms/step - loss: 0.0452 - accuracy: 0.9793 - val_loss: 1.6221 - val_accuracy: 0.7717\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 17s 80ms/step - loss: 0.0433 - accuracy: 0.9807 - val_loss: 1.5806 - val_accuracy: 0.7703\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 16s 76ms/step - loss: 0.0400 - accuracy: 0.9799 - val_loss: 1.9527 - val_accuracy: 0.7664\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_4_history = model_4.fit(\n",
    "    x = train_sentences,\n",
    "    y = train_labels,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_4_bidirectional\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 76.64041994750657,\n",
       " 'Precision Score': 76.72955974842768,\n",
       " 'Recall Score': 70.11494252873564,\n",
       " 'F1-Score': 73.27327327327329}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_4_results = evaluate(y_true=val_labels,\n",
    "                            preds=tf.squeeze(tf.round(model_4.predict(val_sentences))))\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks for Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape = (1, ), dtype = \"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Conv1D(filters = 64, kernel_size = 5, strides = 1, \n",
    "                    activation = \"relu\", padding = \"valid\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name = \"model_5_conv1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_conv1d\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 11, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,321,089\n",
      "Trainable params: 1,321,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 5 summary\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_5.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_5_conv1d/20220601-030244\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 20ms/step - loss: 0.1696 - accuracy: 0.9384 - val_loss: 0.8563 - val_accuracy: 0.7703\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0932 - accuracy: 0.9628 - val_loss: 1.0073 - val_accuracy: 0.7690\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0716 - accuracy: 0.9720 - val_loss: 1.1666 - val_accuracy: 0.7638\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0618 - accuracy: 0.9737 - val_loss: 1.3029 - val_accuracy: 0.7559\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0538 - accuracy: 0.9764 - val_loss: 1.3979 - val_accuracy: 0.7585\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_5_history = model_5.fit(\n",
    "    x = train_sentences,\n",
    "    y = train_labels,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_5_conv1d\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 75.8530183727034,\n",
       " 'Precision Score': 75.46583850931677,\n",
       " 'Recall Score': 69.82758620689656,\n",
       " 'F1-Score': 72.53731343283582}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_5_evaluate = evaluate(y_true=val_labels,\n",
    "                            preds = tf.squeeze(tf.round(model_5.predict(val_sentences))))\n",
    "model_5_evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Tensorflow Hub Pre-trained Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # embed -> because this model helps with embedding, not classification, use dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentence encoder layer\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape = [],\n",
    "                                        dtype = tf.string,\n",
    "                                        trainable = False,\n",
    "                                        name = \"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = tf.keras.Sequential([\n",
    "                                sentence_encoder_layer,\n",
    "                                layers.Dense(64, activation = \"relu\"),\n",
    "                                layers.Dense(1, activation = \"sigmoid\")\n",
    "                            ], name = \"model_6_USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_6.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_6_USE/20220601-030349\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 11s 23ms/step - loss: 0.5098 - accuracy: 0.7787 - val_loss: 0.4472 - val_accuracy: 0.8018\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4167 - accuracy: 0.8142 - val_loss: 0.4368 - val_accuracy: 0.8110\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.4011 - accuracy: 0.8224 - val_loss: 0.4317 - val_accuracy: 0.8150\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.3924 - accuracy: 0.8240 - val_loss: 0.4301 - val_accuracy: 0.8136\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.3850 - accuracy: 0.8288 - val_loss: 0.4277 - val_accuracy: 0.8202\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_6_history = model_6.fit(\n",
    "    x = train_sentences,\n",
    "    y = train_labels,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_6_USE\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 82.02099737532808,\n",
       " 'Precision Score': 85.04983388704319,\n",
       " 'Recall Score': 73.5632183908046,\n",
       " 'F1-Score': 78.89060092449924}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_6_results = evaluate(y_true = val_labels,\n",
    "                            preds = tf.squeeze(tf.round(model_6.predict(val_sentences))))\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Life - We have little data to work with 🙁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset for 10% of the data only\n",
    "train_10_percent_split = int(0.1 * len(train_sentences))\n",
    "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
    "train_labels_10_percent = train_labels[:train_10_percent_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    406\n",
       "1    279\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the targets\n",
    "import numpy as np\n",
    "pd.Series(np.array(train_labels_10_percent)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7 -> Cloned Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = tf.keras.models.clone_model(model_6)\n",
    "\n",
    "#compile model\n",
    "model_7.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_7_USE_10_percent_data/20220601-030430\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 9s 100ms/step - loss: 0.6687 - accuracy: 0.7095 - val_loss: 0.6483 - val_accuracy: 0.7428\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 51ms/step - loss: 0.6001 - accuracy: 0.8058 - val_loss: 0.5929 - val_accuracy: 0.7664\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.5266 - accuracy: 0.8277 - val_loss: 0.5391 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 50ms/step - loss: 0.4645 - accuracy: 0.8248 - val_loss: 0.5041 - val_accuracy: 0.7756\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 49ms/step - loss: 0.4232 - accuracy: 0.8321 - val_loss: 0.4897 - val_accuracy: 0.7808\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_7_history = model_7.fit(\n",
    "    x = train_sentences_10_percent,\n",
    "    y = train_labels_10_percent,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_7_USE_10_percent_data\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Score': 78.08398950131233,\n",
       " 'Precision Score': 79.28802588996764,\n",
       " 'Recall Score': 70.40229885057471,\n",
       " 'F1-Score': 74.5814307458143}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_7_results = evaluate(y_true = val_labels,\n",
    "                            preds = tf.squeeze(tf.round(model_7.predict(val_sentences))))\n",
    "model_7_results             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>88.617886</td>\n",
       "      <td>62.643678</td>\n",
       "      <td>73.400673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_1_Dense</th>\n",
       "      <td>78.215223</td>\n",
       "      <td>81.597222</td>\n",
       "      <td>67.528736</td>\n",
       "      <td>73.899371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_2_LSTM</th>\n",
       "      <td>76.377953</td>\n",
       "      <td>80.882353</td>\n",
       "      <td>63.218391</td>\n",
       "      <td>70.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_3_GRU</th>\n",
       "      <td>77.690289</td>\n",
       "      <td>79.470199</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>73.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_4_bidirectional</th>\n",
       "      <td>76.640420</td>\n",
       "      <td>76.729560</td>\n",
       "      <td>70.114943</td>\n",
       "      <td>73.273273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_5_Conv1D</th>\n",
       "      <td>75.853018</td>\n",
       "      <td>75.465839</td>\n",
       "      <td>69.827586</td>\n",
       "      <td>72.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_6_USE</th>\n",
       "      <td>82.020997</td>\n",
       "      <td>85.049834</td>\n",
       "      <td>73.563218</td>\n",
       "      <td>78.890601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_7_USE_10%</th>\n",
       "      <td>78.083990</td>\n",
       "      <td>79.288026</td>\n",
       "      <td>70.402299</td>\n",
       "      <td>74.581431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Accuracy Score  Precision Score  Recall Score  \\\n",
       "Baseline                    79.265092        88.617886     62.643678   \n",
       "Model_1_Dense               78.215223        81.597222     67.528736   \n",
       "Model_2_LSTM                76.377953        80.882353     63.218391   \n",
       "Model_3_GRU                 77.690289        79.470199     68.965517   \n",
       "Model_4_bidirectional       76.640420        76.729560     70.114943   \n",
       "Model_5_Conv1D              75.853018        75.465839     69.827586   \n",
       "Model_6_USE                 82.020997        85.049834     73.563218   \n",
       "Model_7_USE_10%             78.083990        79.288026     70.402299   \n",
       "\n",
       "                        F1-Score  \n",
       "Baseline               73.400673  \n",
       "Model_1_Dense          73.899371  \n",
       "Model_2_LSTM           70.967742  \n",
       "Model_3_GRU            73.846154  \n",
       "Model_4_bidirectional  73.273273  \n",
       "Model_5_Conv1D         72.537313  \n",
       "Model_6_USE            78.890601  \n",
       "Model_7_USE_10%        74.581431  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_results = pd.DataFrame({\n",
    "    \"Baseline\": baseline_results,\n",
    "    \"Model_1_Dense\": model_1_results,\n",
    "    \"Model_2_LSTM\": model_2_results,\n",
    "    \"Model_3_GRU\": model_3_results,\n",
    "    \"Model_4_bidirectional\": model_4_results,\n",
    "    \"Model_5_Conv1D\": model_5_evaluate,\n",
    "    \"Model_6_USE\": model_6_results,\n",
    "    \"Model_7_USE_10%\": model_7_results\n",
    "})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_model_results.plot(kind = \"bar\", figsize = (10, 7)).legend(bbox_to_anchor = (1.0, 1.0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Been through 8 models - nothing seems to be overly good.\n",
    "\n",
    "### Model 8: Using Universal Sentence Encoder + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 15, 64)\n",
      "(None, 15, 64)\n",
      "(None, 15, 64)\n",
      "(None, 15, 64)\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/losses.py\", line 1930, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/backend.py\", line 5283, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 15, 1) vs (None,)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/vbgupta/Desktop/Code/Tensorflow-Developer-Cert/src/notebooks/nlp/nlp-fundamentals.ipynb Cell 84'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vbgupta/Desktop/Code/Tensorflow-Developer-Cert/src/notebooks/nlp/nlp-fundamentals.ipynb#ch0000105?line=18'>19</a>\u001b[0m model_8\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vbgupta/Desktop/Code/Tensorflow-Developer-Cert/src/notebooks/nlp/nlp-fundamentals.ipynb#ch0000105?line=19'>20</a>\u001b[0m \toptimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vbgupta/Desktop/Code/Tensorflow-Developer-Cert/src/notebooks/nlp/nlp-fundamentals.ipynb#ch0000105?line=20'>21</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vbgupta/Desktop/Code/Tensorflow-Developer-Cert/src/notebooks/nlp/nlp-fundamentals.ipynb#ch0000105?line=22'>23</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vbgupta/Desktop/Code/Tensorflow-Developer-Cert/src/notebooks/nlp/nlp-fundamentals.ipynb#ch0000105?line=23'>24</a>\u001b[0m model_8_history \u001b[39m=\u001b[39m model_8\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vbgupta/Desktop/Code/Tensorflow-Developer-Cert/src/notebooks/nlp/nlp-fundamentals.ipynb#ch0000105?line=24'>25</a>\u001b[0m     x \u001b[39m=\u001b[39;49m train_sentences, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vbgupta/Desktop/Code/Tensorflow-Developer-Cert/src/notebooks/nlp/nlp-fundamentals.ipynb#ch0000105?line=25'>26</a>\u001b[0m     y \u001b[39m=\u001b[39;49m train_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vbgupta/Desktop/Code/Tensorflow-Developer-Cert/src/notebooks/nlp/nlp-fundamentals.ipynb#ch0000105?line=26'>27</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(val_sentences, val_labels),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vbgupta/Desktop/Code/Tensorflow-Developer-Cert/src/notebooks/nlp/nlp-fundamentals.ipynb#ch0000105?line=27'>28</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/kn/rflwhs_x05q34765t1lr06fh0000gn/T/__autograph_generated_fileyy3mgdd5.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     <a href='file:///var/folders/kn/rflwhs_x05q34765t1lr06fh0000gn/T/__autograph_generated_fileyy3mgdd5.py?line=12'>13</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///var/folders/kn/rflwhs_x05q34765t1lr06fh0000gn/T/__autograph_generated_fileyy3mgdd5.py?line=13'>14</a>\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> <a href='file:///var/folders/kn/rflwhs_x05q34765t1lr06fh0000gn/T/__autograph_generated_fileyy3mgdd5.py?line=14'>15</a>\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     <a href='file:///var/folders/kn/rflwhs_x05q34765t1lr06fh0000gn/T/__autograph_generated_fileyy3mgdd5.py?line=15'>16</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     <a href='file:///var/folders/kn/rflwhs_x05q34765t1lr06fh0000gn/T/__autograph_generated_fileyy3mgdd5.py?line=16'>17</a>\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/losses.py\", line 1930, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/Users/vbgupta/.pyenv/versions/3.10.1/lib/python3.10/site-packages/keras/backend.py\", line 5283, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 15, 1) vs (None,)).\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "x = layers.LSTM(64, return_sequences = True)(x)\n",
    "print(x.shape)\n",
    "x = layers.LSTM(64, return_sequences = True)(x)\n",
    "print(x.shape)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "print(x.shape)\n",
    "outputs = layers.Dense(1, activation='softmax')(x)\n",
    "print(x.shape)\n",
    "model_8 = tf.keras.Model(inputs, outputs, name = \"model_8_mix\")\n",
    "\n",
    "# Compile the model\n",
    "model_8.compile(loss='binary_crossentropy', \n",
    "\toptimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_8_history = model_8.fit(\n",
    "    x = train_sentences, \n",
    "    y = train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load NLP Models\n",
    "* HDF5 Format\n",
    "* The `Save Model` format - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# model_6.save(\"models/model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load this model in hdf5 format\n",
    "# loaded_model_6 = tf.keras.models.load_model(\"models/model_6.h5\",\n",
    "#                                             custom_objects = {\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model Format\n",
    "# model_6.save(\"models/model_6_savedmodels_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model_6_saved_model = tf.keras.models.load_model(\"models/model_6_savedmodels_format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the most wrong answer examples\n",
    "* If our best model is not perfect, what examples are it getting wrong\n",
    "* Which ones are the most wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 16ms/step\n",
      "24/24 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>predictions</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.742405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>That's the ultimate road to destruction</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>@SetZorah dad why dont you claim me that mean ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.919105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Crack in the path where I wiped out this morni...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.735324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>I liked a @YouTube video from @dannyonpc http:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>762 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  labels  predictions  \\\n",
       "0    DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0          0.0   \n",
       "1    FedEx no longer to transport bioterror germs i...       0          1.0   \n",
       "2    Gunmen kill four in El Salvador bus attack: Su...       1          1.0   \n",
       "3    @camilacabello97 Internally and externally scr...       1          0.0   \n",
       "4    Radiation emergency #preparedness starts with ...       1          1.0   \n",
       "..                                                 ...     ...          ...   \n",
       "757            That's the ultimate road to destruction       0          0.0   \n",
       "758  @SetZorah dad why dont you claim me that mean ...       0          0.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0          1.0   \n",
       "760  Crack in the path where I wiped out this morni...       0          1.0   \n",
       "761  I liked a @YouTube video from @dannyonpc http:...       0          0.0   \n",
       "\n",
       "     probabilities  \n",
       "0         0.210724  \n",
       "1         0.830966  \n",
       "2         0.989556  \n",
       "3         0.247919  \n",
       "4         0.742405  \n",
       "..             ...  \n",
       "757       0.133825  \n",
       "758       0.114361  \n",
       "759       0.919105  \n",
       "760       0.735324  \n",
       "761       0.106979  \n",
       "\n",
       "[762 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe with validation sentences, labels and best performing model predictions and probabilities\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    \"text\": val_sentences,\n",
    "    \"labels\": val_labels,\n",
    "    \"predictions\": tf.squeeze(tf.round(model_6.predict(val_sentences))),\n",
    "    \"probabilities\": tf.squeeze(model_6.predict(val_sentences))\n",
    "})\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>predictions</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.919105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.860566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>I get to smoke my shit in peace</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Why are you deluged with low self-image? Take ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  labels  predictions  \\\n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0          1.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0          1.0   \n",
       "628  @noah_anyname That's where the concentration c...       0          1.0   \n",
       "393  @SonofLiberty357 all illuminated by the bright...       0          1.0   \n",
       "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0          1.0   \n",
       "..                                                 ...     ...          ...   \n",
       "233                    I get to smoke my shit in peace       1          0.0   \n",
       "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1          0.0   \n",
       "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1          0.0   \n",
       "38   Why are you deluged with low self-image? Take ...       1          0.0   \n",
       "23   Ron &amp; Fez - Dave's High School Crush https...       1          0.0   \n",
       "\n",
       "     probabilities  \n",
       "31        0.941575  \n",
       "759       0.919105  \n",
       "628       0.884292  \n",
       "393       0.860566  \n",
       "209       0.855491  \n",
       "..             ...  \n",
       "233       0.051732  \n",
       "411       0.047418  \n",
       "244       0.042397  \n",
       "38        0.038329  \n",
       "23        0.032780  \n",
       "\n",
       "[140 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find wrong preds, and sort by pred probs\n",
    "most_wrong = val_df[val_df[\"labels\"] != val_df[\"predictions\"]].sort_values(\"probabilities\", ascending = False)\n",
    "most_wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "Pred: 1, Prob: 0.8445082306861877\n",
      "\n",
      "Text: The Cafe Run by Acid Attack Survivors in #India http://t.co/XtVRJMRREs http://t.co/ndvlAPJvQL\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Pred: 0, Prob: 0.08521749824285507\n",
      "\n",
      "Text: @ESM_Campy and he used werewolf on me also idiota I was tea bagging your body for like 7 minutes while he was fighting someone else\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Pred: 0, Prob: 0.1070595234632492\n",
      "\n",
      "Text: @JagexSupport can u remove the email of the hijacker pls !! YKJL is my ign. i need to recover but pls block so they dont break bank pin!\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Pred: 0, Prob: 0.09905754029750824\n",
      "\n",
      "Text: Why is it that my pinky feels like it's lit on fire ? #freaky\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Pred: 1, Prob: 0.9944483041763306\n",
      "\n",
      "Text: Arson suspect linked to 30 fires caught in Northern California http://t.co/HkFPyNb4PS\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Pred: 0, Prob: 0.3246365487575531\n",
      "\n",
      "Text: Oh god Diane is following them to the hostage exchange in a taxi. \n",
      "#RandomActsOfRomance\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Pred: 1, Prob: 0.8360134959220886\n",
      "\n",
      "Text: Sooooo shooting up movie theaters the new mass murderer wave??\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Pred: 1, Prob: 0.7286221981048584\n",
      "\n",
      "Text: Be safe and be prepare from emergency kits to evacuation. Alertness esp women and children who are also @gmanews  https://t.co/3GALBowItN\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Pred: 1, Prob: 0.7092519402503967\n",
      "\n",
      "Text: The EFAK would be designed for building occupants once they evacuate and report to their evacuation assembly sites\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Pred: 0, Prob: 0.13967689871788025\n",
      "\n",
      "Text: VAL JUST DIED AND IM ABSOLUTELY DEVASTATED #emmerdale\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = test_data[\"text\"].to_list()\n",
    "\n",
    "# Making predictions of 10 test sentences and visualizing them\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "    pred_probs = tf.squeeze(model_6.predict([test_sample]))\n",
    "    pred = tf.round(pred_probs)\n",
    "    print(f\"Pred: {int(pred)}, Prob: {pred_probs}\\n\")\n",
    "    print(f\"Text: {test_sample}\\n\")\n",
    "    print(\"-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  id\n",
       "0                 Just happened a terrible car crash   0\n",
       "1  Heard about #earthquake is different cities, s...   2\n",
       "2  there is a forest fire at spot pond, geese are...   3\n",
       "3           Apocalypse lighting. #Spokane #wildfires   9\n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan  11"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Test Data\n",
    "test_data[[\"text\", \"id\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'target'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Submission File - Kaggle\n",
    "sub_file = pd.read_csv(\"data/nlp-getting-started/sample_submission.csv\")\n",
    "print(sub_file.columns)\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 2s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file = pd.DataFrame({\n",
    "    \"id\": test_data[\"id\"],\n",
    "    \"target\": tf.squeeze(tf.round(model_6.predict(test_data[\"text\"].to_list())))\n",
    "})\n",
    "submission_file[\"target\"] = submission_file[\"target\"].astype(int)\n",
    "submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file.to_csv(\"data/nlp-getting-started-submission-1.csv\", index = False) # 0.80570 -> accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Tweets from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "Elon's Tweet is: 0\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Tesla Plaid S cruising around Austin with volume at 11 is sublime\" #thanks elon\n",
    "\n",
    "answer = int(tf.squeeze(tf.round(model_6.predict([sentence]))))\n",
    "print(f\"Elon's Tweet is: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e2db2fe913eb9e94297199806106f5b16655b08f59047963fa319e06216a9ba"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('3.10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
