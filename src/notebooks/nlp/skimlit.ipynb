{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone Project 2 SkimLit\n",
    "\n",
    "- The purpose is to build an NLP model to read medical asbstracts. \n",
    "- Paper being replicated is: https://arxiv.org/abs/1710.06071\n",
    "- Model being replicated that the above paper used: https://arxiv.org/abs/1612.05251\n",
    "\n",
    "\n",
    "Adapted from Course - ZTM Tensorflow Developer Certificate Course 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "Data is available at: https://github.com/Franck-Dernoncourt/pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mPubMed_200k_RCT\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mPubMed_200k_RCT_numbers_replaced_with_at_sign\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mPubMed_20k_RCT\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mPubMed_20k_RCT_numbers_replaced_with_at_sign\u001b[m\u001b[m\n",
      "README.md\n"
     ]
    }
   ],
   "source": [
    "!ls pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt   test.txt  train.txt\n"
     ]
    }
   ],
   "source": [
    "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
    "# dev.txt is the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the experiments with 20k RCT numbers replaced with `@` sign\n",
    "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all the file names in data\n",
    "import os\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read files of a document\n",
    "\n",
    "def get_lines(filename):\n",
    "    \"\"\"\n",
    "    Reads filename and returns the lines of text as a list\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training lines\n",
    "train_lines = get_lines(data_dir + \"train.txt\")\n",
    "train_lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to separate labels from text -> Dict\n",
    "\n",
    "def preprocess_text_with_line_numbers(filename):\n",
    "    \"\"\"\n",
    "    Return a list of dicts of abstract line data\n",
    "    \"\"\"\n",
    "    input_lines = get_lines(filename)\n",
    "    abstract_lines = \"\"\n",
    "    abstract_samples = []\n",
    "\n",
    "    # loop through each line in target file\n",
    "    for line in input_lines:\n",
    "\n",
    "        if line.startswith(\"###\"):\n",
    "            \n",
    "            abstract_id = line\n",
    "            abstract_lines = \"\"\n",
    "        \n",
    "        elif line.isspace():\n",
    "\n",
    "            abstract_lines_split = abstract_lines.splitlines()\n",
    "\n",
    "            for abstract_line_number, abstract_line in enumerate(abstract_lines_split):\n",
    "\n",
    "                line_data = {}\n",
    "\n",
    "                target_text_split = abstract_line.split(\"\\t\")\n",
    "\n",
    "                line_data[\"target\"] = target_text_split[0]\n",
    "\n",
    "                line_data[\"text\"] = target_text_split[1].lower()\n",
    "\n",
    "                line_data[\"line_number\"] = abstract_line_number\n",
    "\n",
    "                line_data[\"total_lines\"] = len(abstract_lines_split) -1\n",
    "\n",
    "                abstract_samples.append(line_data)\n",
    "        else: # line contains a labeled sentence\n",
    "\n",
    "            abstract_lines += line\n",
    "\n",
    "    return abstract_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 11}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data and preprocess it\n",
    "\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir+\"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
    "train_samples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  line_number  \\\n",
       "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
       "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
       "2    METHODS  outcome measures included pain reduction and i...            2   \n",
       "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
       "4    METHODS  secondary outcome measures included the wester...            4   \n",
       "\n",
       "   total_lines  \n",
       "0           11  \n",
       "1           11  \n",
       "2           11  \n",
       "3           11  \n",
       "4           11  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To better Viz the data -> List of Dict => DataFrame\n",
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_samples)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHODS        59353\n",
       "RESULTS        57953\n",
       "CONCLUSIONS    27168\n",
       "BACKGROUND     21727\n",
       "OBJECTIVE      13839\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check distribution of training data\n",
    "train_df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check the length of the different lines\n",
    "train_df[\"total_lines\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       " 'these differences remained significant at @ weeks .']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert abstract text lines to list\n",
    "train_sentences = train_df[\"text\"].to_list()\n",
    "val_sentences = val_df[\"text\"].to_list()\n",
    "test_sentences = test_df[\"text\"].to_list()\n",
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert target labels to numeric\n",
    "\n",
    "# One hot encode labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot = OneHotEncoder(sparse=False) # non spare matrix\n",
    "train_labels_one_hot = one_hot.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "train_labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels_one_hot = one_hot.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "test_labels_one_hot = one_hot.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 4, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encode Labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
    "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
    "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
    "train_labels_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long is each sentence on average\n",
    "import numpy as np\n",
    "sent_length = [len(sentence.split()) for sentence in train_sentences]\n",
    "avg_sent_len = np.mean(sent_length)\n",
    "avg_sent_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What's the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sent_length, bins = 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long of a sentence length covers 95% of the training sentences\n",
    "OUTPUT_SEQ_LENGHT = int(np.percentile(sent_length, 95))\n",
    "OUTPUT_SEQ_LENGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import calculate_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Experiments:\n",
    "1. `Model 0`: Baseline\n",
    "2. `Model 1`: Conv1D With Token Embeddings\n",
    "3. `Model 2`: Tensorflow Hub Feature Extractor\n",
    "4. `Model 3`: Model 2 + Character Embeddings\n",
    "5. `Model 4`: Model 3 + Positional Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create pipeline\n",
    "\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "model_0.fit(X = train_sentences,\n",
    "            y = train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218323844829869"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate baseline model on validation dataset\n",
    "model_0.score(X = val_sentences,\n",
    "            y = val_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate baseline results\n",
    "baseline_results = calculate_results(y_true = val_labels_encoded,\n",
    "                                    y_pred = model_0.predict(val_sentences))\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorizer Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words are in the vocab -> Table2 https://arxiv.org/abs/1710.06071\n",
    "\n",
    "MAX_TOKENS = 68_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 23:02:16.211329: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create text vectorizer\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "                                    max_tokens = MAX_TOKENS,\n",
    "                                    output_sequence_length = OUTPUT_SEQ_LENGHT\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt text vectorizer to training sentences\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words in training vocab\n",
    "rct_20k_text_vocab = text_vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Embeddings Layer\n",
    "from tensorflow.keras import layers\n",
    "token_embed = layers.Embedding(input_dim = len(rct_20k_text_vocab),\n",
    "                                output_dim = 128,\n",
    "                                mask_zero = True,\n",
    "                                name = \"token_embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Datasets Using Tensorflow Data API for Faster Performance and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefected datasets\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Conv1D with Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 1d conv model\n",
    "inputs = layers.Input(shape = (1, ), dtype = tf.string)\n",
    "text_vectors = text_vectorizer(inputs)\n",
    "token_embeddings = token_embed(text_vectors)\n",
    "x = layers.Conv1D(64, kernel_size = 5, padding = \"same\",\n",
    "                 activation = \"relu\")(token_embeddings)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(5, activation = \"softmax\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name = \"conv1d_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv1d_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 55)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_1.compile(loss = \"categorical_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])\n",
    "model_1.summary()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 46s 81ms/step - loss: 0.9195 - accuracy: 0.6362 - val_loss: 0.6908 - val_accuracy: 0.7364\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 45s 80ms/step - loss: 0.6617 - accuracy: 0.7539 - val_loss: 0.6321 - val_accuracy: 0.7683\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 45s 81ms/step - loss: 0.6208 - accuracy: 0.7740 - val_loss: 0.6001 - val_accuracy: 0.7856\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 52s 93ms/step - loss: 0.5911 - accuracy: 0.7903 - val_loss: 0.5824 - val_accuracy: 0.7896\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 43s 77ms/step - loss: 0.5911 - accuracy: 0.7909 - val_loss: 0.5617 - val_accuracy: 0.7992\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_model_1 = model_1.fit(train_dataset,\n",
    "                             steps_per_epoch = int(0.1*len(train_dataset)),\n",
    "                             epochs = 5,\n",
    "                             validation_data = val_dataset,\n",
    "                             validation_steps = int(0.1*len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 4s 4ms/step - loss: 0.5608 - accuracy: 0.8019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5608431100845337, 0.8019329905509949]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model on validation\n",
    "model_1.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 4s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.19330067522839,\n",
       " 'precision': 0.801338653829368,\n",
       " 'recall': 0.8019330067522839,\n",
       " 'f1': 0.7989160881248668}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcualte results\n",
    "model_1_results = calculate_results(y_true = val_labels_encoded,\n",
    "                                    y_pred = tf.argmax(model_1.predict(val_dataset), axis = 1))\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 4s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1])>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the prediction probabilities to class to compare with actual labels\n",
    "model_1_preds = tf.argmax(model_1.predict(val_dataset), axis = 1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Transfer Learning Tensorflow Hub Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained USE model\n",
    "import tensorflow_hub as hub\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                    trainable = False, name = \"USE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 11s 15ms/step - loss: 0.9161 - accuracy: 0.6506 - val_loss: 0.7967 - val_accuracy: 0.6922\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 7s 12ms/step - loss: 0.7690 - accuracy: 0.7003 - val_loss: 0.7551 - val_accuracy: 0.7018\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 7s 12ms/step - loss: 0.7532 - accuracy: 0.7119 - val_loss: 0.7386 - val_accuracy: 0.7134\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 7s 13ms/step - loss: 0.7196 - accuracy: 0.7233 - val_loss: 0.7101 - val_accuracy: 0.7297\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 7s 12ms/step - loss: 0.7272 - accuracy: 0.7211 - val_loss: 0.6902 - val_accuracy: 0.7344\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "inputs = layers.Input(shape = [], dtype = tf.string)\n",
    "embeddings = tf_hub_embedding_layer(inputs)\n",
    "x = layers.Dense(128, activation = \"relu\")(embeddings)\n",
    "outputs = layers.Dense(5, activation = \"softmax\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name = \"USE_Model\")\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss = \"categorical_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_model_2 = model_2.fit(train_dataset,\n",
    "                             steps_per_epoch = int(0.1*len(train_dataset)),\n",
    "                             epochs = 5,\n",
    "                             validation_data = val_dataset,\n",
    "                             validation_steps = int(0.1*len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 9s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 73.29206937640672,\n",
       " 'precision': 0.7290210789158778,\n",
       " 'recall': 0.7329206937640672,\n",
       " 'f1': 0.7272477142976872}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_2_results = calculate_results(y_true = val_labels_encoded,\n",
    "                                    y_pred=tf.argmax(model_2.predict(val_dataset), axis =1))\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Character Level + Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to split sentences into characters\n",
    "def split_chars(text):\n",
    "    return \" \".join(list(text))\n",
    "\n",
    "\n",
    "# Text Splitting non-character-level sequences into characters\n",
    "train_chars = [split_chars(sentences) for sentences in train_sentences]\n",
    "val_chars = [split_chars(sentences) for sentences in val_sentences]\n",
    "test_chars = [split_chars(sentences) for sentences in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.3662574983337"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the average character lenght\n",
    "char_len = [len(sentence) for sentence in train_sentences]\n",
    "mean_char_len = np.mean(char_len)\n",
    "mean_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check distribution for sequence at character-level\n",
    "plt.hist(char_len, bins = 10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What character level cover 95% of sequences\n",
    "OUTPUT_SEQ_LENGHT_CHAR = int(np.percentile(char_len, 95))\n",
    "OUTPUT_SEQ_LENGHT_CHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create-char level token vectorizer instance\n",
    "import string\n",
    "NUM_CHAR_TOKENS = len(string.ascii_lowercase +\n",
    "                      string.digits +\n",
    "                      string.punctuation) + 2\n",
    "char_vectorizer = TextVectorization(\n",
    "        max_tokens = NUM_CHAR_TOKENS,\n",
    "        output_sequence_length = OUTPUT_SEQ_LENGHT_CHAR\n",
    "        ,name = \"char_vectorizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt character vectorizer to training characters\n",
    "char_vectorizer.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "['', '[UNK]', 'e', 't', 'i']\n",
      "['', '[UNK]', 'e', 't', 'i', 'a', 'n', 'o', 'r', 's', 'd', 'c', 'l', 'h', 'p', 'm', 'u', 'f', 'g', 'y', 'w', 'v', 'b']\n"
     ]
    }
   ],
   "source": [
    "# Check character vocab stats\n",
    "char_vocab = char_vectorizer.get_vocabulary()\n",
    "print(len(char_vocab))\n",
    "print(char_vocab[:5])\n",
    "print(char_vocab[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedding layer\n",
    "char_embed = layers.Embedding(input_dim = len(char_vocab),\n",
    "                             output_dim = 25, mask_zero = True,\n",
    "                            name = \"char_embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 8s 13ms/step - loss: 1.4565 - accuracy: 0.3496 - val_loss: 1.3929 - val_accuracy: 0.4079\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 7s 13ms/step - loss: 1.3467 - accuracy: 0.4313 - val_loss: 1.3160 - val_accuracy: 0.4521\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 8s 15ms/step - loss: 1.3128 - accuracy: 0.4554 - val_loss: 1.3061 - val_accuracy: 0.4441\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 10s 17ms/step - loss: 1.2920 - accuracy: 0.4612 - val_loss: 1.2877 - val_accuracy: 0.4644\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 1.2874 - accuracy: 0.4585 - val_loss: 1.2768 - val_accuracy: 0.4724\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "inputs = layers.Input(shape = (1, ), dtype = tf.string)\n",
    "char_vectors = char_vectorizer(inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "x = layers.Conv1D(64, kernel_size = 5, padding = \"same\",\n",
    "                    activation = \"relu\")(char_embeddings)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(5, activation = \"softmax\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name = \"model_3_cov1d_char_embeds\")\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(loss = \"categorical_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "# Build the dataset\n",
    "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "history_model_3 = model_3.fit(train_char_dataset,\n",
    "                             steps_per_epoch = int(0.1*len(train_char_dataset)),\n",
    "                             epochs= 5,\n",
    "                             validation_data = val_char_dataset,\n",
    "                             validation_steps = int(0.1*len(val_char_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 6s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 47.32887594333378,\n",
       " 'precision': 0.4272956986176429,\n",
       " 'recall': 0.47328875943333776,\n",
       " 'f1': 0.42828049457863965}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_3_results = calculate_results(y_true = val_labels_encoded,\n",
    "                                    y_pred = tf.argmax(model_3.predict(val_char_dataset), axis = 1))\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Combining Pretrained Token Embedding + Character Embeddings\n",
    "\n",
    "1. Create a token-level embedding (model 1)\n",
    "2. Create a character level embedding (model 3)\n",
    "3. Combine and 1 and 2 with a concatenate layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Token inputs/models\n",
    "\n",
    "token_inputs = layers.Input(shape = [], dtype = tf.string, name = \"token_input\")\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_outputs = layers.Dense(128, activation = \"relu\")(token_embeddings)\n",
    "token_model = tf.keras.Model(inputs = token_inputs, outputs = token_outputs)\n",
    "\n",
    "# 2. Setup char input/model\n",
    "\n",
    "char_inputs = layers.Input(shape = (1, ), dtype = tf.string, name = \"char_input\")\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
    "char_model = tf.keras.Model(inputs = char_inputs, outputs = char_bi_lstm)\n",
    "\n",
    "# 3. Concatenate token and char inputs\n",
    "\n",
    "token_char_concat = layers.Concatenate(name = \"token_char_hybrid\")([\n",
    "    token_model.output, char_model.output\n",
    "])\n",
    "\n",
    "# 4. Build a series of output layers and dropout layer\n",
    "\n",
    "combined_output = layers.Dropout(0.5)(token_char_concat)\n",
    "combined_dense = layers.Dense(128, activation = \"relu\")(combined_output)\n",
    "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
    "output_layer = layers.Dense(5, activation = \"softmax\")(final_dropout)\n",
    "\n",
    "model_4 = tf.keras.Model(inputs = [token_model.input, char_model.input],\n",
    "                        outputs = output_layer,\n",
    "                        name = \"model_4_token_and_char_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# Plot hybrid model\n",
    "from keras.utils import plot_model\n",
    "plot_model(model_4, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_4.compile(loss = \"categorical_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Char and Token data in tf.data Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine tokens and chars\n",
    "train_token_char_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_sentences, train_chars))\n",
    "train_token_char_labels = tf.data.Dataset.from_tensor_slices(\n",
    "    train_labels_one_hot\n",
    ")\n",
    "train_token_char_dataset = tf.data.Dataset.zip((train_token_char_data,\n",
    "train_token_char_labels))\n",
    "train_token_char_dataset = train_token_char_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine tokens and chars - validation\n",
    "val_token_char_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (val_sentences, val_chars))\n",
    "val_token_char_labels = tf.data.Dataset.from_tensor_slices(\n",
    "    val_labels_one_hot\n",
    ")\n",
    "val_token_char_dataset = tf.data.Dataset.zip((val_token_char_data,\n",
    "val_token_char_labels))\n",
    "val_token_char_dataset = val_token_char_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 112s 180ms/step - loss: 0.9874 - accuracy: 0.6033 - val_loss: 0.7824 - val_accuracy: 0.7045\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 85s 152ms/step - loss: 0.8103 - accuracy: 0.6874 - val_loss: 0.7204 - val_accuracy: 0.7244\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 84s 150ms/step - loss: 0.7845 - accuracy: 0.7002 - val_loss: 0.7124 - val_accuracy: 0.7284\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 84s 150ms/step - loss: 0.7491 - accuracy: 0.7179 - val_loss: 0.6742 - val_accuracy: 0.7497\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 85s 150ms/step - loss: 0.7518 - accuracy: 0.7151 - val_loss: 0.6637 - val_accuracy: 0.7510\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_model_4 = model_4.fit(train_token_char_dataset,\n",
    "                            steps_per_epoch = int(0.1*len(train_token_char_dataset)),\n",
    "                            epochs = 5,\n",
    "                            validation_data = val_token_char_dataset,\n",
    "                            validation_steps = int(0.1*len(val_token_char_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 36s 38ms/step - loss: 0.6681 - accuracy: 0.7466\n",
      "[0.668080747127533, 0.7465576529502869]\n",
      "945/945 [==============================] - 35s 37ms/step\n",
      "{'accuracy': 74.65576592082617, 'precision': 0.7453997813731088, 'recall': 0.7465576592082617, 'f1': 0.7411538515393846}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(model_4.evaluate(val_token_char_dataset))\n",
    "\n",
    "model_4_results = calculate_results(y_true = val_labels_encoded,\n",
    "                                y_pred = tf.argmax(model_4.predict(val_token_char_dataset), axis = 1))\n",
    "print(model_4_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Pretrained Embeddings + Character Embeddings + Positional Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     15000\n",
       "1     15000\n",
       "2     15000\n",
       "3     15000\n",
       "4     14992\n",
       "5     14949\n",
       "6     14758\n",
       "7     14279\n",
       "8     13346\n",
       "9     11981\n",
       "10    10041\n",
       "11     7892\n",
       "12     5853\n",
       "13     4152\n",
       "14     2835\n",
       "15     1861\n",
       "16     1188\n",
       "17      751\n",
       "18      462\n",
       "19      286\n",
       "20      162\n",
       "21      101\n",
       "22       66\n",
       "23       33\n",
       "24       22\n",
       "25       14\n",
       "26        7\n",
       "27        4\n",
       "28        3\n",
       "29        1\n",
       "30        1\n",
       "Name: line_number, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many line numbers are there?\n",
    "train_df[\"line_number\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of line number\n",
    "train_df.line_number.plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5, 15), dtype=float32, numpy=\n",
       " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>,\n",
       " TensorShape([180040, 15]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use tensorflow to create one-hot-encoded tensors for line numbers\n",
    "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth = 15)\n",
    "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth = 15)\n",
    "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth = 15)\n",
    "train_line_numbers_one_hot[:5], train_line_numbers_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    24468\n",
      "10    23639\n",
      "12    22113\n",
      "9     19400\n",
      "13    18438\n",
      "14    14610\n",
      "8     12285\n",
      "15    10768\n",
      "7      7464\n",
      "16     7429\n",
      "17     5202\n",
      "6      3353\n",
      "18     3344\n",
      "19     2480\n",
      "20     1281\n",
      "5      1146\n",
      "21      770\n",
      "22      759\n",
      "23      264\n",
      "4       215\n",
      "24      200\n",
      "25      182\n",
      "26       81\n",
      "28       58\n",
      "3        32\n",
      "30       31\n",
      "27       28\n",
      "Name: total_lines, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Total lines\n",
    "print(train_df[\"total_lines\"].value_counts())\n",
    "train_df.total_lines.plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the average of a total lines coverage given a 98 percentile\n",
    "np.percentile(train_df.total_lines, 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5, 20), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]], dtype=float32)>,\n",
       " TensorShape([180040, 20]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot total lines\n",
    "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth = 20)\n",
    "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth = 20)\n",
    "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth = 20)\n",
    "\n",
    "train_total_lines_one_hot[:5], train_total_lines_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Inputs\n",
    "token_inputs = layers.Input(shape = [], dtype = tf.string, name = \"token_inputs\")\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_outputs = layers.Dense(128, activation = \"relu\")(token_embeddings)\n",
    "token_model = tf.keras.Model(inputs = token_inputs,\n",
    "                            outputs = token_outputs)\n",
    "\n",
    "# Char Inputs\n",
    "char_inputs = layers.Input(shape = (1, ), dtype = tf.string, name = \"char_inputs\")\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
    "char_model = tf.keras.Model(inputs = char_inputs,\n",
    "                            outputs = char_bi_lstm)\n",
    "\n",
    "# Line Number Inputs\n",
    "line_inputs = layers.Input(shape = (15, ), dtype = tf.float32, name = \"line_inputs\")\n",
    "dense_layer_1 = layers.Dense(32, activation = \"relu\")(line_inputs)\n",
    "line_model = tf.keras.Model(inputs = line_inputs,\n",
    "                            outputs = dense_layer_1)\n",
    "\n",
    "\n",
    "# Total Lines Input\n",
    "total_lines_inputs = layers.Input(shape = (20, ), dtype = tf.float32, name = \"total_line_inputs\")\n",
    "dense_layer_2 = layers.Dense(32, activation = \"relu\")(total_lines_inputs)\n",
    "total_line_model = tf.keras.Model(inputs = total_lines_inputs,\n",
    "                            outputs = dense_layer_2)\n",
    "\n",
    "# Combine the embeddings\n",
    "\n",
    "combined_embeddings = layers.Concatenate(name = \"char_token_hybrid_embeddings\")(\n",
    "    [token_model.output, char_model.output]\n",
    ")\n",
    "\n",
    "# Dropout\n",
    "z = layers.Dense(256, activation = \"relu\")(combined_embeddings)\n",
    "z = layers.Dropout(0.5)(z)\n",
    "\n",
    "\n",
    "# Combined positional embeddings\n",
    "\n",
    "tribrid_embeddings = layers.Concatenate(name = \"char_token_positional_embeddings\")(\n",
    "    [line_model.output, total_line_model.output,\n",
    "    z]\n",
    ")\n",
    "\n",
    "# Create output layer\n",
    "output_layer = layers.Dense(5, activation = \"softmax\", name = \"output_layer\")(tribrid_embeddings)\n",
    "\n",
    "# Model\n",
    "model_5 = tf.keras.Model(inputs = [\n",
    "    line_model.input, total_line_model.input,\n",
    "    token_model.input, char_model.input\n",
    "],\n",
    "outputs = output_layer, name = \"tribrid_embeddings_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tribrid_embeddings_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " char_inputs (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " token_inputs (InputLayer)      [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " char_vectorizer (TextVectoriza  (None, 290)         0           ['char_inputs[0][0]']            \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " USE (KerasLayer)               (None, 512)          256797824   ['token_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " char_embed (Embedding)         (None, 290, 25)      700         ['char_vectorizer[6][0]']        \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 128)          65664       ['USE[3][0]']                    \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 48)          9600        ['char_embed[5][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " char_token_hybrid_embeddings (  (None, 176)         0           ['dense_13[0][0]',               \n",
      " Concatenate)                                                     'bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " line_inputs (InputLayer)       [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " total_line_inputs (InputLayer)  [(None, 20)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 256)          45312       ['char_token_hybrid_embeddings[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 32)           512         ['line_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 32)           672         ['total_line_inputs[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " char_token_positional_embeddin  (None, 320)         0           ['dense_14[0][0]',               \n",
      " gs (Concatenate)                                                 'dense_15[0][0]',               \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 5)            1605        ['char_token_positional_embedding\n",
      "                                                                 s[0][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256,921,889\n",
      "Trainable params: 124,065\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary of Model\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model_5.compile(loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2),\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tribrid embeddings dataset using tf.data\n",
    "\n",
    "train_char_token_pos_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_line_numbers_one_hot, train_total_lines_one_hot,\n",
    "    train_sentences, train_chars)\n",
    ")\n",
    "train_char_token_pos_labels = tf.data.Dataset.from_tensor_slices(\n",
    "    train_labels_one_hot\n",
    ")\n",
    "train_char_token_pos_dataset = tf.data.Dataset.zip(\n",
    "    (train_char_token_pos_data, train_char_token_pos_labels)\n",
    ")\n",
    "train_char_token_pos_dataset = train_char_token_pos_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tribrid embeddings dataset using tf.data - validation\n",
    "\n",
    "val_char_token_pos_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (val_line_numbers_one_hot, val_total_lines_one_hot,\n",
    "    val_sentences, val_chars)\n",
    ")\n",
    "val_char_token_pos_labels = tf.data.Dataset.from_tensor_slices(\n",
    "    val_labels_one_hot\n",
    ")\n",
    "val_char_token_pos_dataset = tf.data.Dataset.zip(\n",
    "    (val_char_token_pos_data, val_char_token_pos_labels)\n",
    ")\n",
    "val_char_token_pos_dataset = val_char_token_pos_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tribrid embeddings dataset using tf.data - test\n",
    "\n",
    "test_char_token_pos_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_line_numbers_one_hot, test_total_lines_one_hot,\n",
    "    test_sentences, test_chars)\n",
    ")\n",
    "test_char_token_pos_labels = tf.data.Dataset.from_tensor_slices(\n",
    "    test_labels_one_hot\n",
    ")\n",
    "test_char_token_pos_dataset = tf.data.Dataset.zip(\n",
    "    (test_char_token_pos_data, test_char_token_pos_labels)\n",
    ")\n",
    "test_char_token_pos_dataset = test_char_token_pos_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=((TensorSpec(shape=(None, 15), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_char_token_pos_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 152s 259ms/step - loss: 0.9987 - accuracy: 0.7969 - val_loss: 0.9689 - val_accuracy: 0.8128\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 113s 201ms/step - loss: 0.9582 - accuracy: 0.8226 - val_loss: 0.9407 - val_accuracy: 0.8371\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 100s 178ms/step - loss: 0.9451 - accuracy: 0.8278 - val_loss: 0.9359 - val_accuracy: 0.8368\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 140s 249ms/step - loss: 0.9365 - accuracy: 0.8370 - val_loss: 0.9261 - val_accuracy: 0.8364\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 152s 271ms/step - loss: 0.9340 - accuracy: 0.8391 - val_loss: 0.9227 - val_accuracy: 0.8428\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_model_5 = model_5.fit(train_char_token_pos_dataset,\n",
    "                             steps_per_epoch = int(0.1*len(train_char_token_pos_dataset)),\n",
    "                             epochs = 5,\n",
    "                             validation_data = val_char_token_pos_dataset,\n",
    "                             validation_steps = int(0.1*len(val_char_token_pos_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 60s 64ms/step - loss: 0.9209 - accuracy: 0.8427\n",
      "[0.9209386110305786, 0.8427445888519287]\n",
      "945/945 [==============================] - 42s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 84.27446047927975,\n",
       " 'precision': 0.8455186635162628,\n",
       " 'recall': 0.8427446047927976,\n",
       " 'f1': 0.8387264740327381}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(model_5.evaluate(val_char_token_pos_dataset))\n",
    "\n",
    "model_5_results = calculate_results(\n",
    "    y_true = val_labels_encoded,\n",
    "    y_pred = tf.argmax(model_5.predict(val_char_token_pos_dataset), axis = 1)\n",
    ")\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_0_baseline</th>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.698925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_1_custom_tokens_embed</th>\n",
       "      <td>0.801933</td>\n",
       "      <td>0.801339</td>\n",
       "      <td>0.801933</td>\n",
       "      <td>0.798916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2_pretrained_tokens_embed_USE</th>\n",
       "      <td>0.732921</td>\n",
       "      <td>0.729021</td>\n",
       "      <td>0.732921</td>\n",
       "      <td>0.727248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3_custom_char_embeddings</th>\n",
       "      <td>0.473289</td>\n",
       "      <td>0.427296</td>\n",
       "      <td>0.473289</td>\n",
       "      <td>0.428280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4_char_token_embeddings</th>\n",
       "      <td>0.746558</td>\n",
       "      <td>0.745400</td>\n",
       "      <td>0.746558</td>\n",
       "      <td>0.741154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5_char_token_pos_embeddings</th>\n",
       "      <td>0.842745</td>\n",
       "      <td>0.845519</td>\n",
       "      <td>0.842745</td>\n",
       "      <td>0.838726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     accuracy  precision    recall        f1\n",
       "model_0_baseline                     0.721832   0.718647  0.721832  0.698925\n",
       "model_1_custom_tokens_embed          0.801933   0.801339  0.801933  0.798916\n",
       "model_2_pretrained_tokens_embed_USE  0.732921   0.729021  0.732921  0.727248\n",
       "model_3_custom_char_embeddings       0.473289   0.427296  0.473289  0.428280\n",
       "model_4_char_token_embeddings        0.746558   0.745400  0.746558  0.741154\n",
       "model_5_char_token_pos_embeddings    0.842745   0.845519  0.842745  0.838726"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Results\n",
    "\n",
    "all_model_results = pd.DataFrame(\n",
    "    {\n",
    "      \"model_0_baseline\": baseline_results,\n",
    "      \"model_1_custom_tokens_embed\": model_1_results,\n",
    "      \"model_2_pretrained_tokens_embed_USE\": model_2_results,\n",
    "      \"model_3_custom_char_embeddings\": model_3_results,\n",
    "      \"model_4_char_token_embeddings\": model_4_results,\n",
    "      \"model_5_char_token_pos_embeddings\": model_5_results\n",
    "    }\n",
    ")\n",
    "all_model_results = all_model_results.T\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_model_results.plot(kind = \"bar\", figsize = (10, 7)).legend(\n",
    "    bbox_to_anchor = (1.0, 1.0)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model 5 to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/skimlit_tribrit_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/skimlit_tribrit_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save model 5 in the save model format\n",
    "model_5.save(\"models/skimlit_tribrit_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 00:30:41.759727: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:30:41.926419: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:30:41.955604: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:30:43.078855: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:30:43.126496: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:30:45.738286: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:30:45.758956: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:30:46.994747: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:30:47.743500: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:30:47.763062: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:23.156336: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:23.422724: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:23.437274: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:23.668430: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:23.683995: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:24.595444: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:24.612728: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:24.641824: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:24.957875: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:24.981698: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:26.716047: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:26.733348: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:26.806264: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:26.851561: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:26.878055: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:27.098338: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:27.128937: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-08 00:31:27.748501: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model_5 = tf.keras.models.load_model(\"models/skimlit_tribrit_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 60s 63ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 84.27446047927975,\n",
       " 'precision': 0.8455186635162628,\n",
       " 'recall': 0.8427446047927976,\n",
       " 'f1': 0.8387264740327381}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the loaded model\n",
    "loaded_model_5_results = calculate_results(\n",
    "    y_true = val_labels_encoded,\n",
    "    y_pred = tf.argmax(loaded_model_5.predict(val_char_token_pos_dataset), axis = 1)\n",
    ")\n",
    "loaded_model_5_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942/942 [==============================] - 65s 69ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30135,), dtype=int64, numpy=array([3, 2, 2, ..., 4, 4, 1])>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = tf.argmax(loaded_model_5.predict(test_char_token_pos_dataset), axis = 1)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 83.79293180686909,\n",
       " 'precision': 0.8397690859604977,\n",
       " 'recall': 0.8379293180686909,\n",
       " 'f1': 0.83403232153347}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the models predictions\n",
    "test_results = calculate_results(\n",
    "    y_true = test_labels_encoded,\n",
    "    y_pred = test_labels\n",
    ")\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e2db2fe913eb9e94297199806106f5b16655b08f59047963fa319e06216a9ba"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('3.10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
