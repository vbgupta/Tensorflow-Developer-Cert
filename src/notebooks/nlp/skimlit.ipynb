{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone Project 2 SkimLit\n",
    "\n",
    "- The purpose is to build an NLP model to read medical asbstracts. \n",
    "- Paper being replicated is: https://arxiv.org/abs/1710.06071\n",
    "- Model being replicated that the above paper used: https://arxiv.org/abs/1612.05251"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "Data is available at: https://github.com/Franck-Dernoncourt/pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mPubMed_200k_RCT\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mPubMed_200k_RCT_numbers_replaced_with_at_sign\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mPubMed_20k_RCT\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mPubMed_20k_RCT_numbers_replaced_with_at_sign\u001b[m\u001b[m\n",
      "README.md\n"
     ]
    }
   ],
   "source": [
    "!ls pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt   test.txt  train.txt\n"
     ]
    }
   ],
   "source": [
    "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
    "# dev.txt is the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the experiments with 20k RCT numbers replaced with `@` sign\n",
    "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all the file names in data\n",
    "import os\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read files of a document\n",
    "\n",
    "def get_lines(filename):\n",
    "    \"\"\"\n",
    "    Reads filename and returns the lines of text as a list\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training lines\n",
    "train_lines = get_lines(data_dir + \"train.txt\")\n",
    "train_lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to separate labels from text -> Dict\n",
    "\n",
    "def preprocess_text_with_line_numbers(filename):\n",
    "    \"\"\"\n",
    "    Return a list of dicts of abstract line data\n",
    "    \"\"\"\n",
    "    input_lines = get_lines(filename)\n",
    "    abstract_lines = \"\"\n",
    "    abstract_samples = []\n",
    "\n",
    "    # loop through each line in target file\n",
    "    for line in input_lines:\n",
    "\n",
    "        if line.startswith(\"###\"):\n",
    "            \n",
    "            abstract_id = line\n",
    "            abstract_lines = \"\"\n",
    "        \n",
    "        elif line.isspace():\n",
    "\n",
    "            abstract_lines_split = abstract_lines.splitlines()\n",
    "\n",
    "            for abstract_line_number, abstract_line in enumerate(abstract_lines_split):\n",
    "\n",
    "                line_data = {}\n",
    "\n",
    "                target_text_split = abstract_line.split(\"\\t\")\n",
    "\n",
    "                line_data[\"target\"] = target_text_split[0]\n",
    "\n",
    "                line_data[\"text\"] = target_text_split[1].lower()\n",
    "\n",
    "                line_data[\"line_number\"] = abstract_line_number\n",
    "\n",
    "                line_data[\"total_lines\"] = len(abstract_lines_split) -1\n",
    "\n",
    "                abstract_samples.append(line_data)\n",
    "        else: # line contains a labeled sentence\n",
    "\n",
    "            abstract_lines += line\n",
    "\n",
    "    return abstract_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 11}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data and preprocess it\n",
    "\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir+\"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
    "train_samples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  line_number  \\\n",
       "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
       "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
       "2    METHODS  outcome measures included pain reduction and i...            2   \n",
       "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
       "4    METHODS  secondary outcome measures included the wester...            4   \n",
       "\n",
       "   total_lines  \n",
       "0           11  \n",
       "1           11  \n",
       "2           11  \n",
       "3           11  \n",
       "4           11  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To better Viz the data -> List of Dict => DataFrame\n",
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_samples)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHODS        59353\n",
       "RESULTS        57953\n",
       "CONCLUSIONS    27168\n",
       "BACKGROUND     21727\n",
       "OBJECTIVE      13839\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check distribution of training data\n",
    "train_df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD6CAYAAABgZXp6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXpklEQVR4nO3df7BfdX3n8efLRCpSkVDSLJNgg21Gl7r+gCvEqe1aGUPAraG7LgtblyzDEGfAro77g+h0FotlJt3ZSqW1bFPJmrgq4k+yJTSNiO32D34EQRDQyRVhSQSSGn6ItrDoe//4fq58DTeXb87N9365N8/HzHfuOe/zOed8PvOd8OKc8/l+v6kqJEnq4kWj7oAkafYyRCRJnRkikqTODBFJUmeGiCSpM0NEktTZ0EIkyauS3NH3eiLJ+5IcnWRbkh3t74LWPkmuSDKe5M4kJ/Yda3VrvyPJ6r76SUnuavtckSTDGo8k6bkyE58TSTIP2AWcAlwE7K2qdUnWAguq6uIkZwC/C5zR2n20qk5JcjSwHRgDCrgNOKmqHk1yC/AfgJuBLcAVVXX9VH055phjaunSpUMZpyTNRbfddtvfV9XCybbNn6E+nAp8p6oeSLIKeEurbwS+BlwMrAI2VS/VbkpyVJJjW9ttVbUXIMk2YGWSrwFHVtVNrb4JOBOYMkSWLl3K9u3bD+rgJGkuS/LA/rbN1DORs4HPtOVFVfVQW34YWNSWFwMP9u2zs9Wmqu+cpC5JmiFDD5EkhwHvAD6377Z21TH0+2lJ1iTZnmT7nj17hn06STpkzMSVyOnA16vqkbb+SLtNRfu7u9V3Acf17bek1aaqL5mk/hxVtb6qxqpqbOHCSW/rSZI6mIkQOYdnb2UBbAYmZlitBq7tq5/bZmktBx5vt722AiuSLGgzuVYAW9u2J5Isb7Oyzu07liRpBgz1wXqSI4C3Ae/uK68DrklyPvAAcFarb6E3M2sc+BFwHkBV7U3yYeDW1u7SiYfswIXAJ4DD6T1Qn/KhuiTp4JqRKb4vJGNjY+XsLEkaXJLbqmpssm1+Yl2S1JkhIknqzBCRJHU2U59Y1yy1dO11Iznv/evePpLzSjowXolIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnQ01RJIcleTzSb6V5N4kb0pydJJtSXa0vwta2yS5Isl4kjuTnNh3nNWt/Y4kq/vqJyW5q+1zRZIMczySpJ817CuRjwJ/VVWvBl4H3AusBW6oqmXADW0d4HRgWXutAa4ESHI0cAlwCnAycMlE8LQ2F/Ttt3LI45Ek9RlaiCR5OfAbwFUAVfV0VT0GrAI2tmYbgTPb8ipgU/XcBByV5FjgNGBbVe2tqkeBbcDKtu3IqrqpqgrY1HcsSdIMGOaVyPHAHuB/Jrk9yceTHAEsqqqHWpuHgUVteTHwYN/+O1ttqvrOSeqSpBkyzBCZD5wIXFlVbwB+yLO3rgBoVxA1xD4AkGRNku1Jtu/Zs2fYp5OkQ8YwQ2QnsLOqbm7rn6cXKo+0W1G0v7vb9l3AcX37L2m1qepLJqk/R1Wtr6qxqhpbuHDhtAYlSXrW0EKkqh4GHkzyqlY6FbgH2AxMzLBaDVzbljcD57ZZWsuBx9ttr63AiiQL2gP1FcDWtu2JJMvbrKxz+44lSZoB84d8/N8FPpXkMOA+4Dx6wXVNkvOBB4CzWtstwBnAOPCj1paq2pvkw8Ctrd2lVbW3LV8IfAI4HLi+vSRJM2SoIVJVdwBjk2w6dZK2BVy0n+NsADZMUt8OvGZ6vZQkdeUn1iVJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6myoIZLk/iR3JbkjyfZWOzrJtiQ72t8FrZ4kVyQZT3JnkhP7jrO6td+RZHVf/aR2/PG2b4Y5HknSz5qJK5HfrKrXV9VYW18L3FBVy4Ab2jrA6cCy9loDXAm90AEuAU4BTgYumQie1uaCvv1WDn84kqQJo7idtQrY2JY3Amf21TdVz03AUUmOBU4DtlXV3qp6FNgGrGzbjqyqm6qqgE19x5IkzYBhh0gBf53ktiRrWm1RVT3Ulh8GFrXlxcCDffvubLWp6jsnqT9HkjVJtifZvmfPnumMR5LUZ/6Qj//mqtqV5BeBbUm+1b+xqipJDbkPVNV6YD3A2NjY0M8nSYeKoV6JVNWu9nc38CV6zzQeabeiaH93t+a7gOP6dl/SalPVl0xSlyTNkKGFSJIjkrxsYhlYAXwT2AxMzLBaDVzbljcD57ZZWsuBx9ttr63AiiQL2gP1FcDWtu2JJMvbrKxz+44lSZoBw7ydtQj4Upt1Ox/4dFX9VZJbgWuSnA88AJzV2m8BzgDGgR8B5wFU1d4kHwZube0uraq9bflC4BPA4cD17SVJmiFDC5Gqug943ST17wOnTlIv4KL9HGsDsGGS+nbgNdPurCSpEz+xLknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKmzgUIkyT8bdkckSbPPoFcif5bkliQXJnn5UHskSZo1BgqRqvp14HeA44Dbknw6yduG2jNJ0gvewM9EqmoH8HvAxcA/B65I8q0k/3JYnZMkvbAN+kzktUkuB+4F3gr8VlX907Z8+RD7J0l6AZs/YLs/AT4OfLCq/mGiWFXfS/J7Q+mZJOkFb9DbWW8HPj0RIElelOSlAFX1yal2TDIvye1J/rKtH5/k5iTjST6b5LBW/7m2Pt62L+07xgda/dtJTuurr2y18SRrD2jkkqRpGzREvgIc3rf+0lYbxHvp3Qab8IfA5VX1K8CjwPmtfj7waKtf3tqR5ATgbOBXgZX0ZorNSzIP+BhwOnACcE5rK0maIYPeznpJVT05sVJVT05ciUwlyRJ6VzGXAe9PEnrPUf5ta7IR+BBwJbCqLQN8HvjT1n4VcHVVPQV8N8k4cHJrN15V97VzXd3a3jPgmPQCtnTtdSM79/3r3j6yc0uzzaBXIj9McuLESpKTgH+Yov2EPwb+C/CTtv4LwGNV9Uxb3wksbsuLgQcB2vbHW/uf1vfZZ391SdIMGfRK5H3A55J8DwjwT4B/M9UOSf4FsLuqbkvylmn0cdqSrAHWALziFa8YZVckaU4ZKESq6tYkrwZe1Urfrqr/9zy7/RrwjiRnAC8BjgQ+ChyVZH672lgC7Grtd9H7MOPOJPOBlwPf76tP6N9nf/V9+78eWA8wNjZWz9NvSdKADuQLGN8IvBY4kd5D7HOnalxVH6iqJVW1lN6D8a9W1e8ANwLvbM1WA9e25c1tnbb9q1VVrX52m711PLAMuAW4FVjWZnsd1s6x+QDGI0mapoGuRJJ8Evhl4A7gx61cwKYO57wYuDrJHwC3A1e1+lXAJ9uD8730QoGqujvJNfQemD8DXFRVP279eg+wFZgHbKiquzv0R5LU0aDPRMaAE9qVwQGrqq8BX2vL9/Hs7Kr+Nv8I/Ov97H8ZvRle+9a3AFu69EmSNH2D3s76Jr2H6ZIk/dSgVyLHAPckuQV4aqJYVe8YSq8kSbPCoCHyoWF2QpI0Ow06xfdvkvwSsKyqvtI+rT5vuF2TJL3QDfpV8BfQ+yqSP2+lxcCXh9QnSdIsMeiD9YvofXjwCfjpD1T94rA6JUmaHQYNkaeq6umJlfaJcj/5LUmHuEFD5G+SfBA4vP22+ueA/z28bkmSZoNBQ2QtsAe4C3g3vQ/4+YuGknSIG3R21k+Av2gvSZKAwb8767tM8gykql550HskSZo1DuS7sya8hN53XB198LsjSZpNBnomUlXf73vtqqo/pvezt5KkQ9igt7NO7Ft9Eb0rk0GvYiRJc9SgQfBHfcvPAPcDZx303kiSZpVBZ2f95rA7IkmafQa9nfX+qbZX1UcOTnckSbPJgczOeiPP/ob5b9H7nfMdw+iUNEpL1143kvPev865Kpp9Bg2RJcCJVfUDgCQfAq6rqncNq2OSpBe+Qb/2ZBHwdN/6060mSTqEDXolsgm4JcmX2vqZwMah9EiSNGsMOjvrsiTXA7/eSudV1e3D65YkaTYY9HYWwEuBJ6rqo8DOJMdP1TjJS5LckuQbSe5O8vutfnySm5OMJ/lsksNa/efa+njbvrTvWB9o9W8nOa2vvrLVxpOsPZCBS5Kmb9Cfx70EuBj4QCu9GPhfz7PbU8Bbq+p1wOuBlUmWA38IXF5VvwI8Cpzf2p8PPNrql7d2JDkBOBv4VWAl8GdJ5iWZB3wMOB04ATintZUkzZBBr0R+G3gH8EOAqvoe8LKpdqieJ9vqi9urgLfS+7126D1XObMtr+LZ5yyfB05Nkla/uqqeqqrvAuPAye01XlX3tV9dvLq1lSTNkEFD5OmqKtrXwSc5YpCd2hXDHcBuYBvwHeCxqnqmNdkJLG7Li4EHAdr2x4Ff6K/vs8/+6pKkGTJoiFyT5M+Bo5JcAHyFAX6gqqp+XFWvp/c5k5OBV3ft6HQkWZNke5Lte/bsGUUXJGlOet7ZWe2W0mfpBcATwKuA/1pV2wY9SVU9luRG4E30gmh+u9pYAuxqzXYBx9F7aD8feDnw/b76hP599lff9/zrgfUAY2Njz/lxLUlSN897JdJuY22pqm1V9Z+r6j8NEiBJFiY5qi0fDrwNuBe4EXhna7YauLYtb27rtO1fbefeDJzdZm8dDyyj95UrtwLL2myvw+g9fJ/4WhZJ0gwY9MOGX0/yxqq69QCOfSywsc2iehFwTVX9ZZJ7gKuT/AFwO3BVa38V8Mkk48BeeqFAVd2d5BrgHnpfQ39RVf0YIMl7gK3APGBDVd19AP2TJE3ToCFyCvCuJPfTm6EVehcpr93fDlV1J/CGSer30Xs+sm/9H+n97O5kx7oMuGyS+hZgy2BDkCQdbFOGSJJXVNX/BU6bqp0k6dD0fFciX6b37b0PJPlCVf2rGeiTJGmWeL4H6+lbfuUwOyJJmn2eL0RqP8uSJD3v7azXJXmC3hXJ4W0Znn2wfuRQeydJekGbMkSqat5MdUSSNPscyFfBS5L0MwwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJng/4olUZo6drrRt0FSZqUVyKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqbGghkuS4JDcmuSfJ3Une2+pHJ9mWZEf7u6DVk+SKJONJ7kxyYt+xVrf2O5Ks7quflOSuts8VSfLcnkiShmWYVyLPAP+xqk4AlgMXJTkBWAvcUFXLgBvaOsDpwLL2WgNcCb3QAS4BTgFOBi6ZCJ7W5oK+/VYOcTySpH0MLUSq6qGq+npb/gFwL7AYWAVsbM02Ame25VXApuq5CTgqybHAacC2qtpbVY8C24CVbduRVXVTVRWwqe9YkqQZMCPPRJIsBd4A3AwsqqqH2qaHgUVteTHwYN9uO1ttqvrOSeqTnX9Nku1Jtu/Zs2d6g5Ek/dTQQyTJzwNfAN5XVU/0b2tXEDXsPlTV+qoaq6qxhQsXDvt0knTIGGqIJHkxvQD5VFV9sZUfabeiaH93t/ou4Li+3Ze02lT1JZPUJUkzZJizswJcBdxbVR/p27QZmJhhtRq4tq9+bpultRx4vN322gqsSLKgPVBfAWxt255Isryd69y+Y0mSZsAwv4Dx14B/B9yV5I5W+yCwDrgmyfnAA8BZbdsW4AxgHPgRcB5AVe1N8mHg1tbu0qra25YvBD4BHA5c316SpBkytBCpqr8D9ve5jVMnaV/ARfs51gZgwyT17cBrptFNSdI0+Il1SVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdTa0EEmyIcnuJN/sqx2dZFuSHe3vglZPkiuSjCe5M8mJffusbu13JFndVz8pyV1tnyuSZFhjkSRNbv4Qj/0J4E+BTX21tcANVbUuydq2fjFwOrCsvU4BrgROSXI0cAkwBhRwW5LNVfVoa3MBcDOwBVgJXD/E8UhDtXTtdSM57/3r3j6S82puGNqVSFX9LbB3n/IqYGNb3gic2VffVD03AUclORY4DdhWVXtbcGwDVrZtR1bVTVVV9ILqTCRJM2qmn4ksqqqH2vLDwKK2vBh4sK/dzlabqr5zkrokaQaN7MF6u4KomThXkjVJtifZvmfPnpk4pSQdEmY6RB5pt6Jof3e3+i7guL52S1ptqvqSSeqTqqr1VTVWVWMLFy6c9iAkST0zHSKbgYkZVquBa/vq57ZZWsuBx9ttr63AiiQL2kyuFcDWtu2JJMvbrKxz+44lSZohQ5udleQzwFuAY5LspDfLah1wTZLzgQeAs1rzLcAZwDjwI+A8gKram+TDwK2t3aVVNfGw/kJ6M8AOpzcry5lZkjTDhhYiVXXOfjadOknbAi7az3E2ABsmqW8HXjOdPkqSpsdPrEuSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ/NH3QFJo7V07XUjO/f9694+snPr4PBKRJLU2ay/EkmyEvgoMA/4eFWtG9a5Rvl/bNJcNKp/U14BHTyz+kokyTzgY8DpwAnAOUlOGG2vJOnQMatDBDgZGK+q+6rqaeBqYNWI+yRJh4zZfjtrMfBg3/pO4JQR9UXSLOFkgoNntofIQJKsAda01SeTfHuU/ZnEMcDfj7oTQzbXx+j4Zr8ZGWP+cNhn2K/pjO+X9rdhtofILuC4vvUlrfYzqmo9sH6mOnWgkmyvqrFR92OY5voYHd/sN9fHOKzxzfZnIrcCy5Icn+Qw4Gxg84j7JEmHjFl9JVJVzyR5D7CV3hTfDVV194i7JUmHjFkdIgBVtQXYMup+TNML9lbbQTTXx+j4Zr+5PsahjC9VNYzjSpIOAbP9mYgkaYQMkRFLcn+Su5LckWT7qPtzMCTZkGR3km/21Y5Osi3JjvZ3wSj7OB37Gd+Hkuxq7+MdSc4YZR+nI8lxSW5Mck+Su5O8t9XnxHs4xfjm0nv4kiS3JPlGG+Pvt/rxSW5OMp7ks21C0vTO5e2s0UpyPzBWVXNmDn6S3wCeBDZV1Wta7b8Be6tqXZK1wIKquniU/exqP+P7EPBkVf33UfbtYEhyLHBsVX09ycuA24AzgX/PHHgPpxjfWcyd9zDAEVX1ZJIXA38HvBd4P/DFqro6yf8AvlFVV07nXF6J6KCrqr8F9u5TXgVsbMsb6f2jnZX2M745o6oeqqqvt+UfAPfS+3aIOfEeTjG+OaN6nmyrL26vAt4KfL7VD8p7aIiMXgF/neS29sn6uWpRVT3Ulh8GFo2yM0PyniR3tttds/JWz76SLAXeANzMHHwP9xkfzKH3MMm8JHcAu4FtwHeAx6rqmdZkJwchPA2R0XtzVZ1I75uIL2q3Sua06t1DnWv3Ua8Efhl4PfAQ8Ecj7c1BkOTngS8A76uqJ/q3zYX3cJLxzan3sKp+XFWvp/dNHicDrx7GeQyREauqXe3vbuBL9N7sueiRdi964p707hH356CqqkfaP9qfAH/BLH8f2330LwCfqqovtvKceQ8nG99cew8nVNVjwI3Am4Cjkkx8PnDSr4k6UIbICCU5oj3YI8kRwArgm1PvNWttBla35dXAtSPsy0E38R/X5reZxe9jeyh7FXBvVX2kb9OceA/3N7459h4uTHJUWz4ceBu9Zz83Au9szQ7Ke+jsrBFK8kp6Vx/Q+/aAT1fVZSPs0kGR5DPAW+h9a+gjwCXAl4FrgFcADwBnVdWsfDi9n/G9hd5tkALuB97d9/xgVknyZuD/AHcBP2nlD9J7bjDr38MpxncOc+c9fC29B+fz6F0sXFNVl7b/5lwNHA3cDryrqp6a1rkMEUlSV97OkiR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6uz/A9i8iwpTRywJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check the length of the different lines\n",
    "train_df[\"total_lines\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       " 'these differences remained significant at @ weeks .']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert abstract text lines to list\n",
    "train_sentences = train_df[\"text\"].to_list()\n",
    "val_sentences = val_df[\"text\"].to_list()\n",
    "test_sentences = test_df[\"text\"].to_list()\n",
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert target labels to numeric\n",
    "\n",
    "# One hot encode labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot = OneHotEncoder(sparse=False) # non spare matrix\n",
    "train_labels_one_hot = one_hot.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "train_labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels_one_hot = one_hot.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "test_labels_one_hot = one_hot.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 4, 1, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encode Labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
    "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
    "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
    "train_labels_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long is each sentence on average\n",
    "import numpy as np\n",
    "sent_length = [len(sentence.split()) for sentence in train_sentences]\n",
    "avg_sent_len = np.mean(sent_length)\n",
    "avg_sent_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What's the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sent_length, bins = 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long of a sentence length covers 95% of the training sentences\n",
    "OUTPUT_SEQ_LENGHT = int(np.percentile(sent_length, 95))\n",
    "OUTPUT_SEQ_LENGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import calculate_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Experiments:\n",
    "1. `Model 0`: Baseline\n",
    "2. `Model 1`: Conv1D With Token Embeddings\n",
    "3. `Model 2`: Tensorflow Hub Feature Extractor\n",
    "4. `Model 3`: Model 2 + Character Embeddings\n",
    "5. `Model 4`: Model 3 + Positional Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create pipeline\n",
    "\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "model_0.fit(X = train_sentences,\n",
    "            y = train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218323844829869"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate baseline model on validation dataset\n",
    "model_0.score(X = val_sentences,\n",
    "            y = val_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate baseline results\n",
    "baseline_results = calculate_results(y_true = val_labels_encoded,\n",
    "                                    y_pred = model_0.predict(val_sentences))\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorizer Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words are in the vocab -> Table2 https://arxiv.org/abs/1710.06071\n",
    "\n",
    "MAX_TOKENS = 68_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text vectorizer\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "                                    max_tokens = MAX_TOKENS,\n",
    "                                    output_sequence_length = OUTPUT_SEQ_LENGHT\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt text vectorizer to training sentences\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words in training vocab\n",
    "rct_20k_text_vocab = text_vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Embeddings Layer\n",
    "from tensorflow.keras import layers\n",
    "token_embed = layers.Embedding(input_dim = len(rct_20k_text_vocab),\n",
    "                                output_dim = 128,\n",
    "                                mask_zero = True,\n",
    "                                name = \"token_embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Datasets Using Tensorflow Data API for Faster Performance and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefected datasets\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Conv1D with Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 1d conv model\n",
    "inputs = layers.Input(shape = (1, ), dtype = tf.string)\n",
    "text_vectors = text_vectorizer(inputs)\n",
    "token_embeddings = token_embed(text_vectors)\n",
    "x = layers.Conv1D(64, kernel_size = 5, padding = \"same\",\n",
    "                 activation = \"relu\")(token_embeddings)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(5, activation = \"softmax\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name = \"conv1d_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv1d_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 55)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 55, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_1.compile(loss = \"categorical_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])\n",
    "model_1.summary()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 44s 78ms/step - loss: 0.9173 - accuracy: 0.6353 - val_loss: 0.6840 - val_accuracy: 0.7387\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 52s 93ms/step - loss: 0.6570 - accuracy: 0.7561 - val_loss: 0.6253 - val_accuracy: 0.7729\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 47s 83ms/step - loss: 0.6158 - accuracy: 0.7742 - val_loss: 0.5942 - val_accuracy: 0.7879\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 41s 73ms/step - loss: 0.5876 - accuracy: 0.7904 - val_loss: 0.5778 - val_accuracy: 0.7886\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 41s 74ms/step - loss: 0.5881 - accuracy: 0.7919 - val_loss: 0.5583 - val_accuracy: 0.8019\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_model_1 = model_1.fit(train_dataset,\n",
    "                             steps_per_epoch = int(0.1*len(train_dataset)),\n",
    "                             epochs = 5,\n",
    "                             validation_data = val_dataset,\n",
    "                             validation_steps = int(0.1*len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 4ms/step - loss: 0.5588 - accuracy: 0.8017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5588036179542542, 0.8017013072967529]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model on validation\n",
    "model_1.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 4s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.17013107374554,\n",
       " 'precision': 0.8007890971108349,\n",
       " 'recall': 0.8017013107374553,\n",
       " 'f1': 0.7985551864156616}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcualte results\n",
    "model_1_results = calculate_results(y_true = val_labels_encoded,\n",
    "                                    y_pred = tf.argmax(model_1.predict(val_dataset), axis = 1))\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 4s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1])>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the prediction probabilities to class to compare with actual labels\n",
    "model_1_preds = tf.argmax(model_1.predict(val_dataset), axis = 1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Transfer Learning Tensorflow Hub Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained USE model\n",
    "import tensorflow_hub as hub\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                    trainable = False, name = \"USE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 7s 11ms/step - loss: 0.9214 - accuracy: 0.6459 - val_loss: 0.7971 - val_accuracy: 0.6895\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.7700 - accuracy: 0.7006 - val_loss: 0.7542 - val_accuracy: 0.7048\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.7528 - accuracy: 0.7111 - val_loss: 0.7378 - val_accuracy: 0.7128\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.7181 - accuracy: 0.7245 - val_loss: 0.7097 - val_accuracy: 0.7307\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.7261 - accuracy: 0.7225 - val_loss: 0.6890 - val_accuracy: 0.7380\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "inputs = layers.Input(shape = [], dtype = tf.string)\n",
    "embeddings = tf_hub_embedding_layer(inputs)\n",
    "x = layers.Dense(128, activation = \"relu\")(embeddings)\n",
    "outputs = layers.Dense(5, activation = \"softmax\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name = \"USE_Model\")\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss = \"categorical_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_model_2 = model_2.fit(train_dataset,\n",
    "                             steps_per_epoch = int(0.1*len(train_dataset)),\n",
    "                             epochs = 5,\n",
    "                             validation_data = val_dataset,\n",
    "                             validation_steps = int(0.1*len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 9s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 73.42777704223488,\n",
       " 'precision': 0.7305273591115358,\n",
       " 'recall': 0.7342777704223488,\n",
       " 'f1': 0.7285696522492813}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_2_results = calculate_results(y_true = val_labels_encoded,\n",
    "                                    y_pred=tf.argmax(model_2.predict(val_dataset), axis =1))\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Character Level + Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e2db2fe913eb9e94297199806106f5b16655b08f59047963fa319e06216a9ba"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('3.10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
